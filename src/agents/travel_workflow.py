# src/agents/travel_workflow.py
import re
import json
from typing import List, Dict, Any,Optional
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage

from src.agents.state import AgentState
from src.utils.token_budget import TokenBudget, token_counter
from src.utils.value_evaluator import InformationValueEvaluator
from src.models.schemas import SearchResult, SearchNote, TravelPlanResult
from src.tools.tools import XiaohongshuSearchTool
from src.models.llm import LLMFactory
from src.services.travel_cache import travel_cache
from src.services.multi_plan_store import multi_plan_store
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field




# å¯¼å…¥ä½ çš„ LLM å·¥å‚
from src.models.llm import LLMFactory, get_llm

# ==================== æœç´¢å…³é”®è¯ç»“æ„åŒ–è¾“å‡º ====================

class CoreSearchQueries(BaseModel):
    """ç¬¬1è½®æ ¸å¿ƒæœç´¢å…³é”®è¯"""
    route: List[str] = Field(
        description="è·¯çº¿è§„åˆ’ç›¸å…³æœç´¢è¯ï¼Œ1-2ä¸ªï¼Œå¦‚'XX 3å¤©2æ™šè¡Œç¨‹å®‰æ’'"
    )
    food: List[str] = Field(
        description="ç¾é£Ÿç›¸å…³æœç´¢è¯ï¼Œ1-2ä¸ªï¼Œå¦‚'XX å¿…åƒç¾é£Ÿæ¨è'"
    )
    accommodation: List[str] = Field(
        description="ä½å®¿ç›¸å…³æœç´¢è¯ï¼Œ1-2ä¸ªï¼Œå¦‚'XX ä½å“ªé‡Œæ–¹ä¾¿'"
    )
    attraction: List[str] = Field(
        description="æ™¯ç‚¹æ”»ç•¥ç›¸å…³æœç´¢è¯ï¼Œ1-2ä¸ªï¼Œå¦‚'XX å¿…å»æ™¯ç‚¹æ”»ç•¥'"
    )
    preference: List[str] = Field(
        default=[],
        description="æ ¹æ®ç”¨æˆ·åå¥½ç”Ÿæˆçš„é¢å¤–æœç´¢è¯ï¼Œ0-2ä¸ª"
    )


class SupplementSearchQueries(BaseModel):
    """è¡¥å……æœç´¢å…³é”®è¯"""
    queries: List[str] = Field(
        description="è¡¥å……æœç´¢å…³é”®è¯åˆ—è¡¨ï¼Œ2-4ä¸ª"
    )
    reasoning: str = Field(
        description="ä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›å…³é”®è¯çš„ç®€çŸ­è¯´æ˜"
    )


# ==================== ä¿®å¤åçš„ Prompt æ¨¡æ¿ ====================

CORE_SEARCH_PROMPT = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æœç´¢ä¸“å®¶ï¼Œéœ€è¦ä¸ºç”¨æˆ·ç”Ÿæˆå°çº¢ä¹¦æœç´¢å…³é”®è¯ã€‚

## ç”¨æˆ·ä¿¡æ¯
- ç›®çš„åœ°ï¼š{destination}
- å¤©æ•°ï¼š{days}å¤©
- åå¥½ï¼š{preferences}
- å‡ºè¡Œäººæ•°/ç±»å‹ï¼š{travel_type}

## ä»»åŠ¡
ç”Ÿæˆæœç´¢å…³é”®è¯ï¼Œ**å¿…é¡»è¦†ç›–ä»¥ä¸‹4ä¸ªæ ¸å¿ƒé¢†åŸŸ**ï¼š

1. **è·¯çº¿è§„åˆ’** (route)ï¼šå¦‚ä½•å®‰æ’æ¯å¤©è¡Œç¨‹
   - ç¤ºä¾‹ï¼šã€Œæˆéƒ½3å¤©2æ™šè¡Œç¨‹å®‰æ’ã€ã€Œè¥¿å®‰4æ—¥æ¸¸è·¯çº¿ã€

2. **ç¾é£Ÿæ¨è** (food)ï¼šå½“åœ°å¿…åƒç¾é£Ÿ
   - ç¤ºä¾‹ï¼šã€Œæˆéƒ½å¿…åƒç¾é£Ÿæ”»ç•¥ã€ã€Œæœ¬åœ°äººæ¨èçš„æˆéƒ½å°åƒã€

3. **ä½å®¿æ¨è** (accommodation)ï¼šä½åœ¨å“ªé‡Œæ–¹ä¾¿
   - ç¤ºä¾‹ï¼šã€Œæˆéƒ½ä½å“ªé‡Œæ–¹ä¾¿ã€ã€Œæ˜¥ç†™è·¯é™„è¿‘é…’åº—æ¨èã€

4. **æ™¯ç‚¹æ”»ç•¥** (attraction)ï¼šå¿…å»æ™¯ç‚¹å’Œç©æ³•
   - ç¤ºä¾‹ï¼šã€Œæˆéƒ½å¿…å»æ™¯ç‚¹ã€ã€Œæˆéƒ½æ—…æ¸¸æ”»ç•¥ã€

## è¦æ±‚
- å…³é”®è¯è¦**å…·ä½“ã€æ¥åœ°æ°”**ï¼Œé€‚åˆå°çº¢ä¹¦æœç´¢é£æ ¼
- æ¯ä¸ªé¢†åŸŸç”Ÿæˆ **1-2ä¸ª** å…³é”®è¯
- å…³é”®è¯å¿…é¡»åŒ…å«**ç›®çš„åœ°åç§°**
- å¦‚æœç”¨æˆ·æœ‰ç‰¹æ®Šåå¥½ï¼Œåœ¨ preference ä¸­ç”Ÿæˆç›¸å…³å…³é”®è¯

## è¾“å‡ºæ ¼å¼
è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœã€‚"""),
    ("human", "è¯·ç”Ÿæˆæœç´¢å…³é”®è¯ï¼Œç¡®ä¿è¦†ç›–è·¯çº¿ã€ç¾é£Ÿã€ä½å®¿ã€æ™¯ç‚¹è¿™4ä¸ªæ ¸å¿ƒé¢†åŸŸã€‚è¯·è¿”å›JSONæ ¼å¼ã€‚")
])


SUPPLEMENT_SEARCH_PROMPT = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸æœç´¢ä¸“å®¶ï¼Œéœ€è¦ä¸ºç”¨æˆ·ç”Ÿæˆ**è¡¥å……æœç´¢å…³é”®è¯**ã€‚

## ç”¨æˆ·ä¿¡æ¯
- ç›®çš„åœ°ï¼š{destination}
- å¤©æ•°ï¼š{days}å¤©
- åå¥½ï¼š{preferences}

## å·²æœç´¢è¿‡çš„å…³é”®è¯
{searched_queries}

## å½“å‰ç¼ºå¤±/ä¸è¶³çš„ä¿¡æ¯
{missing_info}

## ä»»åŠ¡
é’ˆå¯¹ç¼ºå¤±çš„ä¿¡æ¯ï¼Œç”Ÿæˆæ›´**å…·ä½“ã€ç²¾å‡†**çš„è¡¥å……æœç´¢å…³é”®è¯ã€‚

## ä¿¡æ¯ç±»å‹è¯´æ˜
- places: æ™¯ç‚¹ä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX å°ä¼—æ™¯ç‚¹ã€ã€ŒXX æ™¯ç‚¹è¯¦ç»†æ”»ç•¥ã€
- food: ç¾é£Ÿä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX ç¾é£Ÿè¡—ã€ã€ŒXX æœ¬åœ°äººæ¨èé¤å…ã€
- accommodation: ä½å®¿ä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX é…’åº—æ°‘å®¿æ¨èã€ã€ŒXX ä½å®¿æ”»ç•¥ã€
- transportation: äº¤é€šä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX äº¤é€šæ”»ç•¥ã€ã€ŒXX æ€ä¹ˆå»ã€
- route: è·¯çº¿ä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX è¡Œç¨‹è§„åˆ’ã€ã€ŒXX å‡ æ—¥æ¸¸å®‰æ’ã€
- avoid: é¿å‘ä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX é¿å‘æŒ‡å—ã€ã€ŒXX æ—…æ¸¸æ³¨æ„äº‹é¡¹ã€
- tips: å®ç”¨ä¿¡æ¯ä¸è¶³ â†’ æœã€ŒXX æ—…æ¸¸å¿…å¤‡ã€ã€ŒXX èŠ±è´¹é¢„ç®—ã€

## è¦æ±‚
- **ä¸è¦é‡å¤**å·²æœç´¢çš„å…³é”®è¯
- å…³é”®è¯è¦æ¯”ä¹‹å‰æ›´**å…·ä½“ã€æ›´æœ‰é’ˆå¯¹æ€§**
- ç”Ÿæˆ **2-4ä¸ª** å…³é”®è¯
- å…³é”®è¯å¿…é¡»åŒ…å«ç›®çš„åœ°åç§°

## è¾“å‡ºæ ¼å¼
è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœã€‚"""),
    ("human", "è¯·ç”Ÿæˆè¡¥å……æœç´¢å…³é”®è¯ï¼Œè¿”å›JSONæ ¼å¼ã€‚")
])


# ==================== LLM å…³é”®è¯ç”Ÿæˆå™¨ ====================

class LLMSearchQueryGenerator:
    """
    LLMé©±åŠ¨çš„æœç´¢å…³é”®è¯ç”Ÿæˆå™¨
    
    ä½¿ç”¨ LLMFactory è·å–æ¨¡å‹å®ä¾‹ï¼Œæ”¯æŒå¤šæä¾›å•†
    """
    
    def __init__(self, model_type: str = "light"):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            model_type: æ¨¡å‹ç±»å‹ "light" | "smart" | "default"
        """
        self.model_type = model_type
        self._llm = None
        self._core_chain = None
        self._supplement_chain = None
    
    @property
    def llm(self):
        """æ‡’åŠ è½½ LLM å®ä¾‹"""
        if self._llm is None:
            self._llm = LLMFactory.get(self.model_type)
            print(f"ğŸ” æœç´¢å…³é”®è¯ç”Ÿæˆå™¨ä½¿ç”¨ [{self.model_type}] æ¨¡å‹")
        return self._llm
    
    @property
    def core_chain(self):
        """æ‡’åŠ è½½æ ¸å¿ƒæœç´¢ Chain"""
        if self._core_chain is None:
            # ä½¿ç”¨ method="json_mode" ç¡®ä¿å…¼å®¹æ€§
            self._core_chain = CORE_SEARCH_PROMPT | self.llm.with_structured_output(
                CoreSearchQueries,
                method="json_mode"  # æ˜ç¡®æŒ‡å®š JSON æ¨¡å¼
            )
        return self._core_chain
    
    @property
    def supplement_chain(self):
        """æ‡’åŠ è½½è¡¥å……æœç´¢ Chain"""
        if self._supplement_chain is None:
            self._supplement_chain = SUPPLEMENT_SEARCH_PROMPT | self.llm.with_structured_output(
                SupplementSearchQueries,
                method="json_mode"
            )
        return self._supplement_chain
    
    def generate_core_queries(
        self,
        destination: str,
        days: int,
        preferences: List[str] = None,
        travel_type: str = None
    ) -> List[str]:
        """
        ç”Ÿæˆç¬¬1è½®æ ¸å¿ƒæœç´¢å…³é”®è¯
        ç¡®ä¿è¦†ç›–ï¼šè·¯çº¿ã€ç¾é£Ÿã€ä½å®¿ã€æ™¯ç‚¹
        """
        preferences = preferences or []
        travel_type = travel_type or "è‡ªç”±è¡Œ"
        
        try:
            result: CoreSearchQueries = self.core_chain.invoke({
                "destination": destination,
                "days": days,
                "preferences": "ã€".join(preferences) if preferences else "æ— ç‰¹æ®Šåå¥½",
                "travel_type": travel_type,
            })
            
            # åˆå¹¶æ‰€æœ‰ç±»åˆ«çš„å…³é”®è¯
            all_queries = []
            all_queries.extend(result.route[:2])
            all_queries.extend(result.food[:2])
            all_queries.extend(result.accommodation[:2])
            all_queries.extend(result.attraction[:2])
            all_queries.extend(result.preference[:2])
            
            # å»é‡
            seen = set()
            unique_queries = []
            for q in all_queries:
                if q and q not in seen:
                    unique_queries.append(q)
                    seen.add(q)
            
            print(f"   âœ… LLMç”Ÿæˆ {len(unique_queries)} ä¸ªæ ¸å¿ƒå…³é”®è¯")
            return unique_queries
            
        except Exception as e:
            print(f"âš ï¸ LLMç”Ÿæˆå…³é”®è¯å¤±è´¥: {e}")
            return self._fallback_core_queries(destination, days)
    
    def generate_supplement_queries(
        self,
        destination: str,
        days: int,
        preferences: List[str] = None,
        searched_queries: List[str] = None,
        missing_info: List[str] = None
    ) -> List[str]:
        """ç”Ÿæˆè¡¥å……æœç´¢å…³é”®è¯"""
        preferences = preferences or []
        searched_queries = searched_queries or []
        missing_info = missing_info or ["avoid", "tips"]
        
        try:
            result: SupplementSearchQueries = self.supplement_chain.invoke({
                "destination": destination,
                "days": days,
                "preferences": "ã€".join(preferences) if preferences else "æ— ç‰¹æ®Šåå¥½",
                "searched_queries": "\n".join(f"- {q}" for q in searched_queries) or "æ— ",
                "missing_info": "ã€".join(missing_info),
            })
            
            print(f"   ğŸ’¡ LLMæ€è·¯: {result.reasoning}")
            
            searched_set = set(searched_queries)
            unique_queries = [q for q in result.queries if q not in searched_set]
            
            return unique_queries[:4]
            
        except Exception as e:
            print(f"âš ï¸ LLMç”Ÿæˆè¡¥å……å…³é”®è¯å¤±è´¥: {e}")
            return self._fallback_supplement_queries(destination, missing_info)
    
    def _fallback_core_queries(self, destination: str, days: int) -> List[str]:
        """é™çº§æ–¹æ¡ˆ"""
        print("   âš ï¸ ä½¿ç”¨é™çº§æ¨¡æ¿")
        return [
            f"{destination} {days}å¤©æ—…æ¸¸æ”»ç•¥",
            f"{destination} ç¾é£Ÿæ¨è",
            f"{destination} ä½å®¿æ”»ç•¥",
            f"{destination} å¿…å»æ™¯ç‚¹",
        ]
    
    def _fallback_supplement_queries(self, destination: str, missing_info: List[str]) -> List[str]:
        """é™çº§æ–¹æ¡ˆ"""
        templates = {
            "places": f"{destination} æ™¯ç‚¹æ¨è",
            "food": f"{destination} æœ¬åœ°ç¾é£Ÿ",
            "accommodation": f"{destination} é…’åº—æ¨è",
            "transportation": f"{destination} äº¤é€šæ”»ç•¥",
            "route": f"{destination} è¡Œç¨‹å®‰æ’",
            "avoid": f"{destination} é¿å‘æŒ‡å—",
            "tips": f"{destination} æ—…æ¸¸æ³¨æ„äº‹é¡¹",
        }
        return [templates.get(info, f"{destination} æ—…æ¸¸æ”»ç•¥") for info in missing_info[:3]]


# ==================== å…¨å±€å®ä¾‹ ====================

_query_generator: Optional[LLMSearchQueryGenerator] = None

def get_query_generator(model_type: str = "light") -> LLMSearchQueryGenerator:
    global _query_generator
    if _query_generator is None or _query_generator.model_type != model_type:
        _query_generator = LLMSearchQueryGenerator(model_type=model_type)
    return _query_generator


def reset_query_generator():
    """é‡ç½®ç”Ÿæˆå™¨ï¼ˆç”¨äºæµ‹è¯•æˆ–é‡æ–°åŠ è½½é…ç½®ï¼‰"""
    global _query_generator
    _query_generator = None
    print("ğŸ”„ æœç´¢å…³é”®è¯ç”Ÿæˆå™¨å·²é‡ç½®")


def search_node(state: AgentState) -> AgentState:
    """
    æœç´¢èŠ‚ç‚¹
    
    ç¬¬1è½®: ä½¿ç”¨ LLM ç”Ÿæˆæ ¸å¿ƒæœç´¢å…³é”®è¯ï¼ˆè·¯çº¿ã€ç¾é£Ÿã€ä½å®¿ã€æ™¯ç‚¹ï¼‰
    ç¬¬2è½®+: æ ¹æ®ç¼ºå¤±ä¿¡æ¯ï¼Œä½¿ç”¨ LLM ç”Ÿæˆè¡¥å……æœç´¢å…³é”®è¯
    """
    search_count = state.get("_search_count", 0) + 1
    state["_search_count"] = search_count
    
    print(f"\n{'='*50}")
    print(f"ğŸ” SEARCH NODE (ç¬¬ {search_count} è½®)")
    print(f"{'='*50}")
    
    user: UserProfile = state["user_profile"]
    budget: TokenBudget = state.get("_token_budget") or TokenBudget()
    searched: List[str] = state.get("_searched_queries", [])
    missing: List[str] = state.get("_missing_info", [])
    
    # è·å– LLM å…³é”®è¯ç”Ÿæˆå™¨
    query_generator = get_query_generator(model_type="light")
    
    # æ ¹æ®æœç´¢è½®æ¬¡ç”Ÿæˆä¸åŒçš„å…³é”®è¯
    if search_count == 1:
        # ç¬¬1è½®ï¼šæ ¸å¿ƒæœç´¢
        print("ğŸ¯ ç›®æ ‡: æ ¸å¿ƒä¿¡æ¯ï¼ˆè·¯çº¿ + ç¾é£Ÿ + ä½å®¿ + æ™¯ç‚¹ï¼‰")
        
        # æ¨æ–­å‡ºè¡Œç±»å‹
        travel_type = _infer_travel_type(user.preferences)
        
        queries = query_generator.generate_core_queries(
            destination=user.destination,
            days=user.days,
            preferences=user.preferences,
            travel_type=travel_type
        )
    else:
        # ç¬¬2è½®+ï¼šè¡¥å……æœç´¢
        if missing:
            print(f"ğŸ¯ ç›®æ ‡: è¡¥å……ç¼ºå¤±ä¿¡æ¯ {missing}")
        else:
            print("ğŸ¯ ç›®æ ‡: è¡¥å……æœç´¢ï¼ˆé¿å‘ + å®ç”¨ä¿¡æ¯ï¼‰")
            missing = ["avoid", "tips"]  # é»˜è®¤è¡¥å……é¿å‘å’Œå®ç”¨ä¿¡æ¯
        
        queries = query_generator.generate_supplement_queries(
            destination=user.destination,
            days=user.days,
            preferences=user.preferences,
            searched_queries=searched,
            missing_info=missing
        )
    
    if not queries:
        print("âš ï¸ æ²¡æœ‰æ–°çš„æœç´¢å…³é”®è¯")
        return state
    
    print(f"\nğŸ“ æœç´¢å…³é”®è¯:")
    for q in queries:
        print(f"   â€¢ {q}")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = InformationValueEvaluator(
        destination=user.destination,
        days=user.days,
        preferences=user.preferences
    )
    
    search_tool = XiaohongshuSearchTool()
    all_notes = []
    
    print(f"\nğŸ” æ‰§è¡Œæœç´¢:")
    for keyword in queries:
        # æ£€æŸ¥ç¼“å­˜
        cached = travel_cache.get_search_results(keyword)
        if cached:
            all_notes.extend(cached)
            print(f"   âœ… [ç¼“å­˜] {keyword}: {len(cached)} æ¡")
            continue
        
        # å®é™…æœç´¢
        try:
            res = search_tool._run(keyword=keyword)
            data = json.loads(res)
            
            if "error" not in data:
                notes = data.get("notes", [])
                all_notes.extend(notes)
                travel_cache.set_search_results(keyword, notes)
                print(f"   âœ… [æœç´¢] {keyword}: {len(notes)} æ¡")
            else:
                print(f"   âš ï¸ [å¤±è´¥] {keyword}: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            print(f"   âŒ [å¼‚å¸¸] {keyword}: {e}")
    
    # è¿‡æ»¤å’Œè¯„ä¼°
    if all_notes:
        print(f"\nğŸ“Š ç¬”è®°è¯„ä¼°:")
        print(f"   åŸå§‹æ•°é‡: {len(all_notes)}")
        
        filtered = evaluator.filter_and_compress(
            all_notes,
            max_notes=budget.max_notes_per_search,
            max_chars_per_note=budget.max_note_length
        )
        
        print(f"   ç­›é€‰å: {len(filtered)} æ¡")
        
        # æ‰“å°ç­›é€‰ç»“æœ
        for note in filtered[:3]:
            print(f"   â€¢ [{note.get('score', 0):.2f}] {note['title'][:40]}...")
        
        # åˆå¹¶åˆ°ç°æœ‰ç¬”è®°ï¼ˆå»é‡ï¼‰
        existing = []
        existing_titles = set()
        
        if state.get("search_results") and state["search_results"].notes:
            for n in state["search_results"].notes:
                existing.append(n)
                existing_titles.add(n.title)
        
        new_count = 0
        for note in filtered:
            if note["title"] not in existing_titles:
                existing.append(SearchNote(
                    title=note["title"],
                    content=note["content"],
                    likes=note.get("likes", 0),
                ))
                existing_titles.add(note["title"])
                new_count += 1
        
        print(f"   æ–°å¢ç¬”è®°: {new_count} æ¡")
        
        state["search_results"] = SearchResult(notes=existing)
    
    # æ›´æ–°çŠ¶æ€
    state["_searched_queries"] = searched + queries
    state["_missing_info"] = []  # æ¸…ç©ºï¼Œç­‰ check èŠ‚ç‚¹é‡æ–°è¯„ä¼°
    
    print(f"\nğŸ“š ç´¯è®¡ç¬”è®°: {len(state.get('search_results', SearchResult(notes=[])).notes)} æ¡")
    
    return state


def _infer_travel_type(preferences: List[str]) -> str:
    """æ ¹æ®ç”¨æˆ·åå¥½æ¨æ–­å‡ºè¡Œç±»å‹"""
    if not preferences:
        return "è‡ªç”±è¡Œ"
    
    prefs_lower = [p.lower() for p in preferences]
    prefs_text = " ".join(prefs_lower)
    
    if any(keyword in prefs_text for keyword in ["äº²å­", "å¸¦å¨ƒ", "å„¿ç«¥", "å­©å­", "å®å®"]):
        return "äº²å­æ¸¸"
    elif any(keyword in prefs_text for keyword in ["æƒ…ä¾£", "çº¦ä¼š", "èœœæœˆ", "æµªæ¼«", "ä¸¤ä¸ªäºº"]):
        return "æƒ…ä¾£æ¸¸"
    elif any(keyword in prefs_text for keyword in ["é—ºèœœ", "æœ‹å‹", "å¥½å‹"]):
        return "é—ºèœœ/æœ‹å‹æ¸¸"
    elif any(keyword in prefs_text for keyword in ["ä¸€ä¸ªäºº", "ç‹¬è‡ª", "solo"]):
        return "ç‹¬è‡ªæ—…è¡Œ"
    elif any(keyword in prefs_text for keyword in ["å®¶åº­", "å…¨å®¶", "çˆ¶æ¯", "è€äºº"]):
        return "å®¶åº­æ¸¸"
    else:
        return "è‡ªç”±è¡Œ"





# # ==================== æœç´¢æ¨¡æ¿é…ç½® ====================

# # æ ¸å¿ƒæœç´¢æ¨¡æ¿ï¼ˆç¬¬1è½®å¿…æœï¼‰
# CORE_SEARCH_TEMPLATES = [
#     "{dest} {days}å¤©æ—…æ¸¸æ”»ç•¥",
#     "{dest} æ—…æ¸¸è·¯çº¿æ¨è",
#     "{dest} ç¾é£Ÿæ”»ç•¥",
#     "{dest} ä½å®¿æ¨è",
# ]

# # è¡¥å……æœç´¢æ¨¡æ¿ï¼ˆæŒ‰ç±»åˆ«ï¼‰
# SUPPLEMENT_TEMPLATES = {
#     "places": [
#         "{dest} å¿…å»æ™¯ç‚¹",
#         "{dest} æ™¯ç‚¹æ¨èæ”»ç•¥",
#     ],
#     "food": [
#         "{dest} å¿…åƒç¾é£Ÿæ¨è",
#         "{dest} æœ¬åœ°äººæ¨èç¾é£Ÿ",
#         "{dest} ç¾é£Ÿè¡—",
#     ],
#     "transportation": [
#         "{dest} äº¤é€šæ”»ç•¥",
#         "{dest} æ€ä¹ˆå» åœ°é“å…¬äº¤",
#     ],
#     "accommodation": [
#         "{dest} ä½å“ªé‡Œæ–¹ä¾¿",
#         "{dest} é…’åº—æ°‘å®¿æ¨è",
#     ],
#     "avoid": [
#         "{dest} é¿å‘æŒ‡å—",
#         "{dest} æ—…æ¸¸æ³¨æ„äº‹é¡¹",
#     ],
# }

# # åå¥½å…³é”®è¯æ˜ å°„
# PREFERENCE_KEYWORDS = {
#     "ç‰¹ç§å…µ": ["æš´èµ°æ”»ç•¥", "ä¸€æ—¥æ¸¸"],
#     "ä¼‘é—²": ["æ…¢æ¸¸", "æ‚ é—²åº¦å‡"],
#     "äº²å­": ["äº²å­æ¸¸", "å¸¦å¨ƒæ”»ç•¥"],
#     "æƒ…ä¾£": ["æƒ…ä¾£çº¦ä¼š", "æµªæ¼«æ‰“å¡"],
#     "æ‹ç…§": ["æ‹ç…§åœ£åœ°", "å‡ºç‰‡æœºä½"],
#     "ç¾é£Ÿ": ["å¿…åƒæ¦œ", "åœ°é“ç¾é£Ÿ"],
#     "å†å²": ["å†å²å¤è¿¹", "åšç‰©é¦†"],
#     "æ·±åº¦": ["æ·±åº¦æ¸¸", "å°ä¼—æ™¯ç‚¹"],
# }


# #==================== æœç´¢å…³é”®è¯ç”Ÿæˆ ====================
# def _generate_search_queries(
#     user_profile,
#     search_count: int,
#     searched: List[str],
#     missing_info: List[str] = None
# ) -> List[str]:
#     """
#     ç”Ÿæˆæœç´¢å…³é”®è¯
    
#     ç­–ç•¥:
#     - ç¬¬1è½®: æ ¸å¿ƒæœç´¢ï¼ˆè·¯çº¿ + ç¾é£Ÿ + ä½å®¿ï¼‰
#     - ç¬¬2è½®+: æ ¹æ®ç¼ºå¤±ä¿¡æ¯è¡¥å……
#     """
#     dest = user_profile.destination
#     days = user_profile.days
#     prefs = user_profile.preferences or []
#     missing_info = missing_info or []
    
#     queries = []
    
#     if search_count == 1:
#         # ========== ç¬¬1è½®: æ ¸å¿ƒæœç´¢ ==========
#         for template in CORE_SEARCH_TEMPLATES:
#             query = template.format(dest=dest, days=days)
#             queries.append(query)
        
#         # æ·»åŠ åå¥½ç›¸å…³æœç´¢
#         for pref in prefs[:2]:  # æœ€å¤š2ä¸ªåå¥½
#             pref_lower = pref.lower()
#             for key, keywords in PREFERENCE_KEYWORDS.items():
#                 if key in pref_lower:
#                     queries.append(f"{dest} {keywords[0]}")
#                     break
    
#     else:
#         # ========== ç¬¬2è½®+: è¡¥å……æœç´¢ ==========
#         if missing_info:
#             for info_type in missing_info:
#                 templates = SUPPLEMENT_TEMPLATES.get(info_type, [])
#                 for template in templates[:2]:  # æ¯ä¸ªç±»åˆ«æœ€å¤š2ä¸ª
#                     query = template.format(dest=dest, days=days)
#                     queries.append(query)
#         else:
#             # æ²¡æœ‰æ˜ç¡®ç¼ºå¤±ï¼Œè¡¥å……é¿å‘ä¿¡æ¯
#             for template in SUPPLEMENT_TEMPLATES.get("avoid", []):
#                 query = template.format(dest=dest, days=days)
#                 queries.append(query)
    
#     # ========== å»é‡è¿‡æ»¤ ==========
#     seen = set(searched)
#     unique = []
#     for q in queries:
#         q = q.strip()
#         if q and q not in seen:
#             unique.append(q)
#             seen.add(q)
    
#     # ç¬¬1è½®å¤šæœä¸€äº›ï¼Œåç»­è½®æ¬¡å°‘æœ
#     max_queries = 4 if search_count == 1 else 3
#     return unique[:max_queries]



# ==================== æœç´¢èŠ‚ç‚¹ ====================

# def search_node(state: AgentState) -> AgentState:
#     """
#     æœç´¢èŠ‚ç‚¹
    
#     ç¬¬1è½®: æœç´¢æ ¸å¿ƒä¿¡æ¯ï¼ˆè·¯çº¿ã€ç¾é£Ÿã€ä½å®¿ï¼‰
#     ç¬¬2è½®+: æ ¹æ®ç¼ºå¤±ä¿¡æ¯è¡¥å……æœç´¢
#     """
#     search_count = state.get("_search_count", 0) + 1
#     state["_search_count"] = search_count
    
#     print(f"\n{'='*50}")
#     print(f"ğŸ” SEARCH NODE (ç¬¬ {search_count} è½®)")
#     print(f"{'='*50}")
    
#     user = state["user_profile"]
#     budget: TokenBudget = state.get("_token_budget") or TokenBudget()
#     searched = state.get("_searched_queries", [])
#     missing = state.get("_missing_info", [])
    
#     # æ‰“å°æœç´¢ç›®æ ‡
#     if search_count == 1:
#         print("ğŸ¯ ç›®æ ‡: æ ¸å¿ƒä¿¡æ¯ï¼ˆè·¯çº¿ + ç¾é£Ÿ + ä½å®¿ï¼‰")
#     elif missing:
#         print(f"ğŸ¯ ç›®æ ‡: è¡¥å……ç¼ºå¤±ä¿¡æ¯ {missing}")
#     else:
#         print("ğŸ¯ ç›®æ ‡: è¡¥å……æœç´¢")
    
#     # ç”Ÿæˆæœç´¢å…³é”®è¯
#     queries = _generate_search_queries(user, search_count, searched, missing)
    
#     if not queries:
#         print("âš ï¸ æ²¡æœ‰æ–°çš„æœç´¢å…³é”®è¯")
#         return state
    
#     print(f"\nğŸ“ æœç´¢å…³é”®è¯:")
#     for q in queries:
#         print(f"   â€¢ {q}")
    
#     # åˆ›å»ºè¯„ä¼°å™¨
#     evaluator = InformationValueEvaluator(
#         destination=user.destination,
#         days=user.days,
#         preferences=user.preferences
#     )
    
#     search_tool = XiaohongshuSearchTool()
#     all_notes = []
    
#     print(f"\nğŸ” æ‰§è¡Œæœç´¢:")
#     for keyword in queries:
#         # æ£€æŸ¥ç¼“å­˜
#         cached = travel_cache.get_search_results(keyword)
#         if cached:
#             all_notes.extend(cached)
#             print(f"   âœ… [ç¼“å­˜] {keyword}: {len(cached)} æ¡")
#             continue
        
#         # å®é™…æœç´¢
#         try:
#             res = search_tool._run(keyword=keyword)
#             data = json.loads(res)
            
#             if "error" not in data:
#                 notes = data.get("notes", [])
#                 all_notes.extend(notes)
#                 travel_cache.set_search_results(keyword, notes)
#                 print(f"   âœ… [æœç´¢] {keyword}: {len(notes)} æ¡")
#             else:
#                 print(f"   âš ï¸ [å¤±è´¥] {keyword}: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
#         except Exception as e:
#             print(f"   âŒ [å¼‚å¸¸] {keyword}: {e}")
    
#     # è¿‡æ»¤å’Œè¯„ä¼°
#     if all_notes:
#         print(f"\nğŸ“Š ç¬”è®°è¯„ä¼°:")
#         print(f"   åŸå§‹æ•°é‡: {len(all_notes)}")
        
#         filtered = evaluator.filter_and_compress(
#             all_notes,
#             max_notes=budget.max_notes_per_search,
#             max_chars_per_note=budget.max_note_length
#         )
        
#         print(f"   ç­›é€‰å: {len(filtered)} æ¡")
        
#         # æ‰“å°ç­›é€‰ç»“æœ
#         for note in filtered[:3]:
#             print(f"   â€¢ [{note.get('score', 0):.2f}] {note['title'][:40]}...")
        
#         # åˆå¹¶åˆ°ç°æœ‰ç¬”è®°ï¼ˆå»é‡ï¼‰
#         existing = []
#         existing_titles = set()
        
#         if state.get("search_results") and state["search_results"].notes:
#             for n in state["search_results"].notes:
#                 existing.append(n)
#                 existing_titles.add(n.title)
        
#         new_count = 0
#         for note in filtered:
#             if note["title"] not in existing_titles:
#                 existing.append(SearchNote(
#                     title=note["title"],
#                     content=note["content"],
#                     likes=note.get("likes", 0),
#                 ))
#                 existing_titles.add(note["title"])
#                 new_count += 1
        
#         print(f"   æ–°å¢ç¬”è®°: {new_count} æ¡")
        
#         state["search_results"] = SearchResult(notes=existing)
    
#     # æ›´æ–°çŠ¶æ€
#     state["_searched_queries"] = searched + queries
#     state["_missing_info"] = []  # æ¸…ç©ºï¼Œç­‰ check èŠ‚ç‚¹é‡æ–°è¯„ä¼°
    
#     print(f"\nğŸ“š ç´¯è®¡ç¬”è®°: {len(state.get('search_results', SearchResult(notes=[])).notes)} æ¡")
    
#     return state

# ==================== æå–èŠ‚ç‚¹ ====================

# ==================== æå–æç¤ºè¯ ====================

EXTRACT_PROMPT = """ä½ æ˜¯ä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹å°çº¢ä¹¦ç¬”è®°ä¸­æå–æ—…è¡Œç›¸å…³ä¿¡æ¯ã€‚

    ã€ç›®çš„åœ°ã€‘{destination}
    ã€ç¬”è®°å†…å®¹ã€‘
    {context}

    è¯·è¾“å‡º JSONï¼Œ**åªå¡«å†™ç¬”è®°ä¸­æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œæ²¡æœ‰çš„å­—æ®µçœç•¥**ï¼š

    ```json
    {{
      "routes": [
        {{
          "source": "ç¬”è®°æ¥æºæ ‡è¯†ï¼ˆå¦‚ï¼šç¬”è®°1ï¼‰",
          "days": 3,
          "description": "è·¯çº¿ç®€è¿°ï¼ˆå¦‚ï¼šç»å…¸3æ—¥æ¸¸ï¼‰",
          "daily_plan": [
            {{
              "day": 1,
              "theme": "ä¸»é¢˜ï¼ˆå¦‚æœ‰ï¼‰",
              "places": ["æ™¯ç‚¹1", "æ™¯ç‚¹2", "æ™¯ç‚¹3"]
            }},
            {{
              "day": 2,
              "theme": "ä¸»é¢˜ï¼ˆå¦‚æœ‰ï¼‰",
              "places": ["æ™¯ç‚¹4", "æ™¯ç‚¹5"]
            }}
          ]
        }}
      ],
      
      "places": [
        {{
          "name": "æ™¯ç‚¹å",
          "open_time": "å¼€æ”¾æ—¶é—´ï¼ˆå¦‚æœ‰ï¼‰",
          "closed_day": "é—­é¦†æ—¥ï¼ˆå¦‚ï¼šå‘¨ä¸€é—­é¦†ï¼‰",
          "ticket": "é—¨ç¥¨ä»·æ ¼ï¼ˆå¦‚æœ‰ï¼‰",
          "duration": "å»ºè®®æ¸¸ç©æ—¶é•¿ï¼ˆå¦‚æœ‰ï¼‰",
          "tips": "æ¸¸ç©æç¤ºï¼ˆå¦‚æœ‰ï¼‰",
          "need_booking": "æ˜¯å¦éœ€è¦é¢„çº¦ï¼ˆå¦‚æœ‰ï¼‰"
        }}
      ],
      
      "transportation": {{
        "arrival": "åˆ°è¾¾äº¤é€šï¼ˆå¦‚ï¼šå—äº¬å—ç«™ï¼Œåœ°é“1å·çº¿ä¾¿æ·ï¼‰",
        "local": ["å¸‚å†…äº¤é€šå»ºè®®1", "å»ºè®®2"]
      }},
      "accommodation": {{
        "recommended_areas": [
          {{
            "area": "åŒºåŸŸåç§°ï¼ˆå¦‚ï¼šæ–°è¡—å£ï¼‰",
            "reasons": ["åŸå› 1", "åŸå› 2", "åŸå› 3"],
            "nearby": ["å‘¨è¾¹è®¾æ–½/æ™¯ç‚¹"],
            "transport": "äº¤é€šä¾¿åˆ©æ€§æè¿°",
            "price_range": "ä»·æ ¼åŒºé—´ï¼ˆå¦‚æœ‰ï¼‰"
          }}
        ],
        "tips": ["ä½å®¿ç›¸å…³å»ºè®®"],
      }},
      "food": {{
        "specialties": [
          {{"name": "ç¾é£Ÿå", "description": "æè¿°ï¼ˆå¦‚æœ‰ï¼‰"}}
        ],
        "restaurants": [
          {{"name": "åº—å", "type": "ç±»å‹ï¼ˆæ—©é¤/åˆé¤ç­‰ï¼‰", "specialty": "æ‹›ç‰Œèœ"}}
        ],
        "streets": [
          {{"name": "ç¾é£Ÿè¡—å", "location": "ä½ç½®", "features": "ç‰¹è‰²"}}
        ]
      }},
      
      "avoid": [
        {{"item": "é¿å‘äº‹é¡¹", "reason": "åŸå› ï¼ˆå¦‚æœ‰ï¼‰"}}
      ],
      
      "tips": ["å®ç”¨è´´å£«1", "è´´å£«2"]
    }}
    æå–åŸåˆ™ï¼š
    âœ… è·¯çº¿ä¿¡æ¯æœ€é‡è¦ï¼šå®Œæ•´ä¿ç•™ç¬”è®°ä¸­çš„ DAY1/DAY2/DAY3 ç­‰è·¯çº¿è§„åˆ’
    âœ… ä½å®¿ä¿¡æ¯è¦è¯¦ç»†ï¼šä¿ç•™æ¨èåŸå› ã€å‘¨è¾¹é…å¥—ã€äº¤é€šä¾¿åˆ©æ€§ç­‰
    âœ… ä¿ç•™å…·ä½“ä¿¡æ¯ï¼šä»·æ ¼ã€æ—¶é—´ã€åœ°å€
    âœ… æ™¯ç‚¹è¯¦æƒ…å•ç‹¬æå–ï¼Œæ–¹ä¾¿åç»­è¡¥å……åˆ°è·¯çº¿ä¸­
    âœ… æ²¡æåˆ°çš„å­—æ®µç›´æ¥çœç•¥
    âŒ ä¸è¦ç¼–é€ ä¿¡æ¯
    âŒ ä¸è¦ä¿®æ”¹åŸå§‹è·¯çº¿é¡ºåº"""

def extract_node(state: AgentState) -> AgentState:
    """æå–èŠ‚ç‚¹ - åªæå–ä¿¡æ¯ï¼Œä¸ç”Ÿæˆè·¯çº¿"""
    print(f"\n{'='*50}")
    print(f"ğŸ“‹ EXTRACT NODE")
    print(f"{'='*50}")

    search_results = state.get("search_results")
    budget: TokenBudget = state.get("_token_budget") or TokenBudget()
    user = state["user_profile"]

    if not search_results or not search_results.notes:
        print("âš ï¸ æ— æœç´¢ç»“æœ")
        state["extracted_info"] = {}
        return state

    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    for i, note in enumerate(search_results.notes):
        text = f"ã€ç¬”è®°{i+1}ã€‘{note.title}\n{note.content}"
        context_parts.append(text)

    context = "\n\n---\n\n".join(context_parts)

    prompt = EXTRACT_PROMPT.format(
        destination=user.destination,
        context=context
    )

    llm = LLMFactory.get_light_model()
    input_tokens = token_counter.count(prompt)

    print(f"ğŸ“Š è¾“å…¥: {input_tokens} tokens ({len(context_parts)} æ¡ç¬”è®°)")
    
    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        output_tokens = token_counter.count(response.content)
        budget.consume("extract", input_tokens + output_tokens)
        
        # âœ… ä½¿ç”¨å®‰å…¨è§£æ
        extracted = _safe_parse_json(response.content, default={})
        
        if not extracted:
            print("âš ï¸ JSON è§£æè¿”å›ç©ºç»“æœ")
        else:
            print(f"ğŸ“ æå–æˆåŠŸ: {len(extracted.get('places', []))} ä¸ªæ™¯ç‚¹")

        # åˆå¹¶åˆ°ç°æœ‰æå–ä¿¡æ¯
        existing = state.get("extracted_info") or {}
        merged = _merge_extracted_info(existing, extracted)
        
        state["extracted_info"] = merged
        
        print(f"âœ… æå–å®Œæˆ ({input_tokens + output_tokens} tokens)")
        _print_extracted_summary(merged)
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # ä¿ç•™ç°æœ‰ä¿¡æ¯æˆ–è®¾ä¸ºç©º
        if not state.get("extracted_info"):
            state["extracted_info"] = {}

    state["_token_budget"] = budget
    return state

def _merge_extracted_info(existing: dict, new: dict) -> dict:
    """
    åˆå¹¶æå–ä¿¡æ¯ï¼ˆå»é‡ï¼‰
    """
    # âœ… æ·»åŠ ç©ºå€¼ä¿æŠ¤
    if existing is None:
        existing = {}
    if new is None:
        new = {}
    merged = existing.copy()
    
    # ==================== åˆå¹¶è·¯çº¿ ====================
    existing_routes = merged.get("routes", [])
    new_routes = new.get("routes", [])
    
    existing_keys = {
        (r.get("source", ""), r.get("days", 0)) 
        for r in existing_routes
    }
    
    for route in new_routes:
        key = (route.get("source", ""), route.get("days", 0))
        if key not in existing_keys:
            existing_routes.append(route)
            existing_keys.add(key)
    
    merged["routes"] = existing_routes
    
    # ==================== åˆå¹¶æ™¯ç‚¹ ====================
    existing_places = {p.get("name"): p for p in merged.get("places", [])}
    for place in new.get("places", []):
        name = place.get("name")
        if name:
            if name in existing_places:
                for k, v in place.items():
                    if v and not existing_places[name].get(k):
                        existing_places[name][k] = v
            else:
                existing_places[name] = place
    merged["places"] = list(existing_places.values())
    
    # ==================== åˆå¹¶äº¤é€š ====================
    if new.get("transportation"):
        if merged.get("transportation"):
            if new["transportation"].get("arrival"):
                existing_arrival = merged["transportation"].get("arrival", "")
                new_arrival = new["transportation"].get("arrival", "")
                if len(new_arrival) > len(existing_arrival):
                    merged["transportation"]["arrival"] = new_arrival
            
            if new["transportation"].get("local"):
                existing_local = set(merged["transportation"].get("local", []))
                new_local = new["transportation"].get("local", [])
                if isinstance(new_local, list):
                    existing_local.update(new_local)
                elif isinstance(new_local, str):
                    existing_local.add(new_local)
                merged["transportation"]["local"] = list(existing_local)
        else:
            merged["transportation"] = new["transportation"]
    
    # ==================== åˆå¹¶ä½å®¿ ====================
    if new.get("accommodation"):
        if not merged.get("accommodation"):
            merged["accommodation"] = {
                "recommended_areas": [],
                "tips": []
            }
        
        existing_acc = merged["accommodation"]
        new_acc = new["accommodation"]
        
        # --- åˆå¹¶æ¨èåŒºåŸŸ ---
        existing_areas = existing_acc.get("recommended_areas", [])
        new_areas = new_acc.get("recommended_areas", [])
        
        existing_area_map = {a.get("area"): a for a in existing_areas if a.get("area")}
        
        for area in new_areas:
            area_name = area.get("area")
            if not area_name:
                continue
                
            if area_name in existing_area_map:
                existing_area = existing_area_map[area_name]
                
                # åˆå¹¶åŸå› 
                existing_reasons = set(existing_area.get("reasons", []))
                new_reasons = area.get("reasons", [])
                if isinstance(new_reasons, list):
                    existing_reasons.update(new_reasons)
                existing_area["reasons"] = list(existing_reasons)
                
                # åˆå¹¶å‘¨è¾¹
                existing_nearby = set(existing_area.get("nearby", []))
                new_nearby = area.get("nearby", [])
                if isinstance(new_nearby, list):
                    existing_nearby.update(new_nearby)
                existing_area["nearby"] = list(existing_nearby)
                
                # è¡¥å……å…¶ä»–å­—æ®µ
                for key in ["transport", "price_range"]:
                    if area.get(key) and not existing_area.get(key):
                        existing_area[key] = area[key]
            else:
                existing_areas.append(area)
                existing_area_map[area_name] = area
        
        existing_acc["recommended_areas"] = existing_areas
        
        # --- åˆå¹¶ä½å®¿ tips ---
        existing_tips = set(existing_acc.get("tips", []))
        new_tips = new_acc.get("tips", [])
        if isinstance(new_tips, list):
            existing_tips.update(new_tips)
        existing_acc["tips"] = list(existing_tips)
        
        merged["accommodation"] = existing_acc
    
    # ==================== åˆå¹¶ç¾é£Ÿ ====================
    if new.get("food"):
        if not merged.get("food"):
            merged["food"] = {
                "specialties": [],
                "restaurants": [],
                "streets": []
            }
        
        existing_food = merged["food"]
        new_food = new["food"]
        
        # åˆå¹¶ç‰¹è‰²ç¾é£Ÿ
        existing_specialties = existing_food.get("specialties", [])
        new_specialties = new_food.get("specialties", [])
        existing_names = set()
        for s in existing_specialties:
            if isinstance(s, dict):
                existing_names.add(s.get("name", ""))
            elif isinstance(s, str):
                existing_names.add(s)
        
        for item in new_specialties:
            name = item.get("name", "") if isinstance(item, dict) else str(item)
            if name and name not in existing_names:
                existing_specialties.append(item)
                existing_names.add(name)
        existing_food["specialties"] = existing_specialties
        
        # åˆå¹¶é¤å…
        existing_restaurants = existing_food.get("restaurants", [])
        new_restaurants = new_food.get("restaurants", [])
        existing_names = {r.get("name") for r in existing_restaurants if isinstance(r, dict) and r.get("name")}
        
        for item in new_restaurants:
            if isinstance(item, dict) and item.get("name") and item.get("name") not in existing_names:
                existing_restaurants.append(item)
                existing_names.add(item.get("name"))
        existing_food["restaurants"] = existing_restaurants
        
        # åˆå¹¶ç¾é£Ÿè¡—
        existing_streets = existing_food.get("streets", [])
        new_streets = new_food.get("streets", [])
        existing_names = set()
        for s in existing_streets:
            if isinstance(s, dict):
                existing_names.add(s.get("name", ""))
            elif isinstance(s, str):
                existing_names.add(s)
        
        for item in new_streets:
            name = item.get("name", "") if isinstance(item, dict) else str(item)
            if name and name not in existing_names:
                existing_streets.append(item)
                existing_names.add(name)
        existing_food["streets"] = existing_streets
        
        merged["food"] = existing_food
    
    # ==================== åˆå¹¶é¿å‘ ====================
    existing_avoid = merged.get("avoid", [])
    new_avoid = new.get("avoid", [])
    existing_items = set()
    for a in existing_avoid:
        if isinstance(a, dict):
            existing_items.add(a.get("item", ""))
        elif isinstance(a, str):
            existing_items.add(a)
    
    for item in new_avoid:
        item_text = item.get("item", "") if isinstance(item, dict) else str(item)
        if item_text and item_text not in existing_items:
            existing_avoid.append(item)
            existing_items.add(item_text)
    merged["avoid"] = existing_avoid
    
    # ==================== åˆå¹¶è´´å£« ====================
    existing_tips = set(merged.get("tips", []))
    new_tips = new.get("tips", [])
    if isinstance(new_tips, list):
        existing_tips.update(new_tips)
    merged["tips"] = list(existing_tips)
    
    return merged

def _print_extracted_summary(extracted: dict):
    """æ‰“å°æå–æ‘˜è¦"""
    routes = extracted.get("routes", [])
    places = extracted.get("places", [])
    food = extracted.get("food", {})
    accommodation = extracted.get("accommodation", {})
    
    print(f"\nğŸ“Š æå–ç»“æœ:")
    
    # è·¯çº¿
    print(f"   ğŸ—ºï¸ è·¯çº¿: {len(routes)} æ¡")
    for i, route in enumerate(routes[:3]):
        days = route.get("days", "?")
        desc = route.get("description", "")[:25]
        daily_plan = route.get("daily_plan", [])
        print(f"      {i+1}. {days}å¤© - {desc} ({len(daily_plan)}å¤©è®¡åˆ’)")
    
    # æ™¯ç‚¹
    print(f"   ğŸ“ æ™¯ç‚¹: {len(places)} ä¸ª")
    detailed = [p for p in places if p.get("ticket") or p.get("open_time")]
    if detailed:
        print(f"      (å…¶ä¸­ {len(detailed)} ä¸ªæœ‰è¯¦ç»†ä¿¡æ¯)")
    
    # ç¾é£Ÿ
    if isinstance(food, dict):
        specialties_count = len(food.get("specialties", []))
        restaurants_count = len(food.get("restaurants", []))
        streets_count = len(food.get("streets", []))
        print(f"   ğŸœ ç¾é£Ÿ: {specialties_count}ç§ç‰¹è‰² + {restaurants_count}å®¶é¤å… + {streets_count}æ¡ç¾é£Ÿè¡—")
    else:
        print(f"   ğŸœ ç¾é£Ÿ: æ— ")
    
    # ä½å®¿
    if isinstance(accommodation, dict):
        areas = accommodation.get("recommended_areas", [])
        tips = accommodation.get("tips", [])
        
        print(f"   ğŸ¨ ä½å®¿: {len(areas)}ä¸ªåŒºåŸŸ, {len(tips)}æ¡å»ºè®®")
        
        for area in areas[:2]:
            area_name = area.get("area", "æœªçŸ¥")
            reasons = area.get("reasons", [])[:3]
            print(f"      â€¢ {area_name}: {', '.join(reasons)}")
    else:
        print(f"   ğŸ¨ ä½å®¿: æ— ")
    
    # äº¤é€š
    transportation = extracted.get("transportation", {})
    if transportation:
        arrival = transportation.get("arrival", "")[:30] if transportation.get("arrival") else ""
        local_count = len(transportation.get("local", []))
        print(f"   ğŸš— äº¤é€š: åˆ°è¾¾-{arrival}..., å¸‚å†…{local_count}æ¡å»ºè®®")
    else:
        print(f"   ğŸš— äº¤é€š: æ— ")
    
    # é¿å‘å’Œè´´å£«
    print(f"   âš ï¸ é¿å‘: {len(extracted.get('avoid', []))} æ¡")
    print(f"   ğŸ’¡ è´´å£«: {len(extracted.get('tips', []))} æ¡")



def check_info_quality(state: AgentState) -> str:
    """æ£€æŸ¥ä¿¡æ¯è´¨é‡ï¼Œå†³å®šæ˜¯å¦ç»§ç»­æœç´¢"""
    print(f"\n{'â”€'*50}")
    print(f"ğŸ” CHECK INFO QUALITY")
    print(f"{'â”€'*50}")
    
    search_count = state.get("_search_count", 0)
    max_searches = state.get("_max_searches", 3)
    
    if search_count >= max_searches:
        print(f"âš ï¸ å·²è¾¾æœ€å¤§æœç´¢æ¬¡æ•° ({max_searches})")
        return "enough"
    
    extracted = state.get("extracted_info", {})
    missing = []
    
    # 1. è·¯çº¿ä¿¡æ¯
    routes = extracted.get("routes", [])
    valid_routes = [r for r in routes if r.get("daily_plan")]
    if len(valid_routes) < 1:
        missing.append("places")
        print(f"   ğŸ—ºï¸ è·¯çº¿: {len(routes)}æ¡ (æœ‰æ•ˆ:{len(valid_routes)}) âŒ")
    else:
        print(f"   ğŸ—ºï¸ è·¯çº¿: {len(routes)}æ¡ (æœ‰æ•ˆ:{len(valid_routes)}) âœ…")
    
    # 2. æ™¯ç‚¹ä¿¡æ¯
    places = extracted.get("places", [])
    if len(places) < 3 and len(valid_routes) < 1:
        if "places" not in missing:
            missing.append("places")
        print(f"   ğŸ“ æ™¯ç‚¹: {len(places)}ä¸ª âŒ")
    else:
        print(f"   ğŸ“ æ™¯ç‚¹: {len(places)}ä¸ª âœ…")
    
    # 3. ç¾é£Ÿä¿¡æ¯
    food = extracted.get("food", {})
    if isinstance(food, dict):
        food_count = (
            len(food.get("specialties", [])) + 
            len(food.get("restaurants", [])) +
            len(food.get("streets", []))
        )
    else:
        food_count = 0
    
    if food_count < 2:
        missing.append("food")
        print(f"   ğŸœ ç¾é£Ÿ: {food_count}é¡¹ âŒ")
    else:
        print(f"   ğŸœ ç¾é£Ÿ: {food_count}é¡¹ âœ…")
    
    # 4. ä½å®¿ä¿¡æ¯
    accommodation = extracted.get("accommodation", {})
    if isinstance(accommodation, dict):
        areas = accommodation.get("recommended_areas", [])
        valid_areas = [a for a in areas if a.get("area")]
        
        if len(valid_areas) < 1:
            missing.append("accommodation")
            print(f"   ğŸ¨ ä½å®¿: æ— æœ‰æ•ˆåŒºåŸŸ âŒ")
        else:
            area_names = [a.get("area", "") for a in valid_areas[:2]]
            print(f"   ğŸ¨ ä½å®¿: {', '.join(area_names)} âœ…")
    else:
        missing.append("accommodation")
        print(f"   ğŸ¨ ä½å®¿: æ—  âŒ")
    
    # 5. äº¤é€šä¿¡æ¯
    if search_count >= 2:
        transportation = extracted.get("transportation")
        if not transportation or not transportation.get("arrival"):
            missing.append("transportation")
            print(f"   ğŸš— äº¤é€š: æ—  âš ï¸")
        else:
            print(f"   ğŸš— äº¤é€š: æœ‰ âœ…")
    
    # 6. é¿å‘ä¿¡æ¯
    avoid = extracted.get("avoid", [])
    print(f"   âš ï¸ é¿å‘: {len(avoid)}æ¡")
    
    if missing:
        state["_missing_info"] = missing
        print(f"\nâ†’ ç»§ç»­æœç´¢ï¼Œç¼ºå¤±: {missing}")
        return "need_more"
    
    print(f"\nâ†’ ä¿¡æ¯å……è¶³ï¼Œå¼€å§‹è§„åˆ’ âœ…")
    return "enough"


# ==================== è§„åˆ’èŠ‚ç‚¹ ====================

PLAN_PROMPT = """ä½ æ˜¯ä¸“ä¸šæ—…è¡Œè§„åˆ’å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆ{days}å¤©{destination}æ—…è¡Œè®¡åˆ’ã€‚

    ã€ç”¨æˆ·ä¿¡æ¯ã€‘
    - å‡ºå‘åœ°: {origin}
    - å¤©æ•°: {days}å¤©
    - äººç¾¤: {group_type}
    - åå¥½: {preferences}

    ã€å·²æ”¶é›†çš„æ”»ç•¥ä¿¡æ¯ã€‘
    {extracted_info}

    ã€ç”Ÿæˆè¦æ±‚ã€‘
    1. **å‚è€ƒå·²æœ‰è·¯çº¿**ï¼šä¸Šé¢çš„ `routes` å­—æ®µåŒ…å«ç½‘å‹æ¨èçš„è·¯çº¿ï¼Œè¯·å‚è€ƒè¿™äº›è·¯çº¿è§„åˆ’è¡Œç¨‹
    2. **ä½¿ç”¨æ™¯ç‚¹è¯¦æƒ…**ï¼š`places` å­—æ®µæœ‰æ™¯ç‚¹çš„å¼€æ”¾æ—¶é—´ã€é—¨ç¥¨ã€é—­é¦†æ—¥ç­‰ä¿¡æ¯ï¼Œè¦ä½“ç°åœ¨è¡Œç¨‹ä¸­
    3. **èå…¥ç¾é£Ÿæ¨è**ï¼š
      - å°† `food.restaurants` ä¸­çš„é¤å…å®‰æ’åˆ°åˆé€‚çš„ç”¨é¤æ—¶é—´
      - å°† `food.specialties` ä¸­çš„ç‰¹è‰²ç¾é£Ÿä½“ç°åœ¨æ¨èä¸­
      - å°† `food.streets` ä¸­çš„ç¾é£Ÿè¡—ä½œä¸ºç”¨é¤åœ°ç‚¹æ¨è
    4. **ä½¿ç”¨ä½å®¿ä¿¡æ¯**ï¼š`accommodation.recommended_areas` åŒ…å«æ¨èåŒºåŸŸå’ŒåŸå› 
    5. **ä½¿ç”¨äº¤é€šä¿¡æ¯**ï¼š`transportation` åŒ…å«åˆ°è¾¾å’Œå¸‚å†…äº¤é€šå»ºè®®
    6. **æ³¨æ„é¿å‘ä¿¡æ¯**ï¼š`avoid` ä¸­çš„äº‹é¡¹è¦åœ¨è¡Œç¨‹æç¤ºä¸­ä½“ç°
    7. æ¯å¤©å®‰æ’ 4-6 ä¸ªæ´»åŠ¨ï¼Œæ—¶é—´åˆç†
    8. æ³¨æ„æ™¯ç‚¹é—­é¦†æ—¥ï¼ˆå¦‚å‘¨ä¸€é—­é¦†ï¼‰ï¼Œåˆç†å®‰æ’

    ç›´æ¥è¾“å‡º JSONï¼š
    ```json
    {{
      "overview": "è¡Œç¨‹æ¦‚è¿°ï¼ˆ50å­—å†…ï¼‰",
      "highlights": ["äº®ç‚¹1", "äº®ç‚¹2", "äº®ç‚¹3"],
      "reference_routes": ["å‚è€ƒçš„è·¯çº¿æ¥æºï¼Œå¦‚ï¼šç¬”è®°1çš„3æ—¥æ¸¸è·¯çº¿"],
      "days": [
        {{
          "day": 1,
          "date": "Day 1",
          "theme": "å½“æ—¥ä¸»é¢˜",
          "schedule": [
            {{
              "time": "09:00-11:00",
              "poi": "æ™¯ç‚¹åç§°ï¼ˆçº¯åè¯ï¼Œå¿…å¡«ï¼‰",
              "activity": "æ´»åŠ¨æè¿°",
              "duration": "2å°æ—¶",
              "ticket": "é—¨ç¥¨ä¿¡æ¯ï¼ˆä» places ä¸­è·å–ï¼Œå¦‚ï¼šå…è´¹/32å…ƒï¼‰",
              "tips": "æ¸¸ç©æç¤ºï¼ˆå¦‚ï¼šéœ€æå‰é¢„çº¦ã€å‘¨ä¸€é—­é¦†ç­‰ï¼‰"
            }}
          ],
          "meals": {{
            "breakfast": {{
              "recommend": "æ¨èé¤å…æˆ–ç¾é£Ÿ",
              "location": "ä½ç½®",
              "reason": "æ¨èåŸå› "
            }},
            "lunch": {{
              "recommend": "æ¨è",
              "location": "ä½ç½®",
              "reason": "æ¨èåŸå› "
            }},
            "dinner": {{
              "recommend": "æ¨è",
              "location": "ä½ç½®",
              "reason": "æ¨èåŸå› "
            }}
          }}
        }}
      ],
      "tips": {{
        "transportation": {{
          "arrival": "åˆ°è¾¾äº¤é€šå»ºè®®",
          "local": ["å¸‚å†…äº¤é€šå»ºè®®1", "å»ºè®®2"]
        }},
        "accommodation": {{
          "area": "æ¨èä½å®¿åŒºåŸŸ",
          "reasons": ["åŸå› 1", "åŸå› 2"],
          "nearby": ["å‘¨è¾¹è®¾æ–½"]
        }},
        "food": {{
          "specialties": [
            {{
              "name": "ç‰¹è‰²ç¾é£Ÿå",
              "description": "ç¾é£Ÿæè¿°",
              "reason": "ä¸ºä»€ä¹ˆæ¨èï¼ˆå¦‚ï¼šå—äº¬å¿…åƒã€æœ¬åœ°äººæ¨èç­‰ï¼‰"
            }}
          ],
          "streets": [
            {{
              "name": "ç¾é£Ÿè¡—å",
              "location": "ä½ç½®",
              "features": "ç‰¹è‰²",
              "reason": "ä¸ºä»€ä¹ˆæ¨è"
            }}
          ],
          "restaurants": [
            {{
              "name": "é¤å…å",
              "specialty": "æ‹›ç‰Œèœ",
              "reason": "ä¸ºä»€ä¹ˆæ¨èï¼ˆå¦‚ï¼šè€å­—å·ã€æœ¬åœ°äººå¸¸å»ç­‰ï¼‰"
            }}
          ]
        }},
        "avoid": [
          {{
            "item": "æ³¨æ„äº‹é¡¹",
            "reason": "åŸå› "
          }}
        ],
        "practical": ["å…¶ä»–å®ç”¨è´´å£«"]
      }}
    }}
    âš ï¸ POI å­—æ®µè§„åˆ™ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
    å¿…é¡»æ˜¯çº¯åè¯ï¼šä»…å¡«å†™åœ°å›¾å¯å®šä½çš„å…·ä½“åœ°ç‚¹åç§°
    è¿”å›çš„poiå¿…é¡»è¦æ˜¯è¿™ä¸ªåŸå¸‚çš„è€Œä¸æ˜¯åˆ«çš„åŸå¸‚
    ä¸¥ç¦åŒ…å«åŠ¨è¯ï¼šåˆ é™¤"å‰å¾€"ã€"æ¸¸è§ˆ"ã€"å‚è§‚"ã€"å¤œæ¸¸"ã€"æ‰“å¡"ç­‰è¯æ±‡
    ç¤ºä¾‹ï¼šâŒ "æ¸¸è§ˆä¸­å±±é™µ" â†’ âœ… "ä¸­å±±é™µ"
    ç¤ºä¾‹ï¼šâŒ "ç§¦æ·®æ²³å¤œæ¸¸" â†’ âœ… "ç§¦æ·®æ²³"
    ä¸è¦å‡ºç°å¤šåœ°ç‚¹ï¼šâŒ "è€é—¨ä¸œ â†’ å¤«å­åº™" â†’ âœ… åˆ†æˆä¸¤ä¸ª schedule é¡¹
    specialtiesä¿¡æ¯å’Œrestaurantsä¿¡æ¯ä¿ç•™å¹¶åŠ ä»¥æ¶¦è‰²ã€‚
    """


def plan_node(state: AgentState) -> AgentState:
    """è§„åˆ’èŠ‚ç‚¹ - ç”Ÿæˆå®Œæ•´è¡Œç¨‹"""
    print(f"\n{'='*50}")
    print(f"ğŸ—“ï¸ PLAN NODE")
    print(f"{'='*50}")

    user = state["user_profile"]
    extracted = state.get("extracted_info") or {}
    budget: TokenBudget = state.get("_token_budget") or TokenBudget()




    prompt = PLAN_PROMPT.format(
        days=user.days,
        destination=user.destination,
        origin=user.origin or "æœªçŸ¥",
        group_type=user.group_type or "æ™®é€šæ¸¸å®¢",
        preferences="ã€".join(user.preferences) if user.preferences else "æ— ç‰¹æ®Šåå¥½",
        extracted_info=json.dumps(extracted, ensure_ascii=False, indent=2)
    )

    llm = LLMFactory.get_smart_model()
    input_tokens = token_counter.count(prompt)

    print(f"ğŸ“Š è¾“å…¥: {input_tokens} tokens")

    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        output_tokens = token_counter.count(response.content)
        budget.consume("plan", input_tokens + output_tokens)
        
        # âœ… ä½¿ç”¨å®‰å…¨è§£æ
        plan = _safe_parse_json(response.content, default={})
        
        if not plan or not plan.get("days"):
            print("âš ï¸ è§„åˆ’ç»“æœä¸å®Œæ•´ï¼Œä½¿ç”¨å…œåº•æ–¹æ¡ˆ")
            plan = _create_fallback_plan(user, extracted)
        
        # è½¬æ¢ä¸ºæœ€ç»ˆç»“æœ
        state["final_result"] = TravelPlanResult(
            destination=user.destination,
            overview=plan.get("overview", ""),
            highlights=plan.get("highlights", []),
            reference_routes=plan.get("reference_routes", []),
            days=plan.get("days", []),
            tips=plan.get("tips", {})
        )
        
        print(f"âœ… è§„åˆ’å®Œæˆ ({input_tokens + output_tokens} tokens)")
        print(f"   ç”Ÿæˆ {len(plan.get('days', []))} å¤©è¡Œç¨‹")
        
    except Exception as e:
        print(f"âŒ è§„åˆ’å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        state["final_result"] = _create_fallback_result(user)

    saved_plan_id = _save_result(state)
    if saved_plan_id:
        state["current_plan_id"] = saved_plan_id

    state["_token_budget"] = budget
    return state


def _create_fallback_plan(user, extracted: dict) -> dict:
    """åˆ›å»ºåŸºäºå·²æå–ä¿¡æ¯çš„å…œåº•è®¡åˆ’"""
    routes = extracted.get("routes", [])
    places = extracted.get("places", [])
    
    days = []
    
    # å°è¯•ä½¿ç”¨å·²æœ‰è·¯çº¿
    if routes:
        best_route = None
        for route in routes:
            route_days = route.get("days", 0)
            if route_days == user.days:
                best_route = route
                break
        
        if not best_route:
            best_route = routes[0]
        
        daily_plan = best_route.get("daily_plan", [])
        for dp in daily_plan[:user.days]:
            days.append({
                "day": dp.get("day", len(days) + 1),
                "date": f"Day {dp.get('day', len(days) + 1)}",
                "theme": dp.get("theme", "æ¸¸è§ˆ"),
                "schedule": [
                    {"time": "09:00", "poi": place, "activity": "æ¸¸è§ˆ", "duration": "2å°æ—¶"}
                    for place in dp.get("places", [])[:5]
                ]
            })
    
    # å¦‚æœæ²¡æœ‰è·¯çº¿ï¼Œä½¿ç”¨æ™¯ç‚¹åˆ—è¡¨
    elif places:
        places_per_day = max(1, len(places) // user.days)
        for day_num in range(user.days):
            start_idx = day_num * places_per_day
            end_idx = start_idx + places_per_day
            day_places = places[start_idx:end_idx]
            
            days.append({
                "day": day_num + 1,
                "date": f"Day {day_num + 1}",
                "theme": "æ¸¸è§ˆ",
                "schedule": [
                    {"time": "09:00", "poi": p.get("name", ""), "activity": "æ¸¸è§ˆ", "duration": "2å°æ—¶"}
                    for p in day_places
                ]
            })
    
    return {
        "overview": f"{user.destination}{user.days}å¤©ä¹‹æ—…",
        "highlights": [],
        "days": days,
        "tips": {}
    }

def _print_planning_input(extracted: dict):
    """æ‰“å°è§„åˆ’è¾“å…¥ä¿¡æ¯"""
    print(f"\nğŸ“‹ è§„åˆ’è¾“å…¥:")
    
    # è·¯çº¿å‚è€ƒ
    routes = extracted.get("routes", [])
    print(f"   ğŸ—ºï¸ å¯å‚è€ƒè·¯çº¿: {len(routes)} æ¡")
    for r in routes[:2]:
        days = r.get("days", "?")
        desc = r.get("description", "")[:20]
        print(f"      â€¢ {days}å¤© - {desc}")
    
    # æ™¯ç‚¹
    places = extracted.get("places", [])
    print(f"   ğŸ“ æ™¯ç‚¹ä¿¡æ¯: {len(places)} ä¸ª")
    
    # ç¾é£Ÿ
    food = extracted.get("food", {})
    if food:
        print(f"   ğŸœ ç¾é£Ÿ: {len(food.get('specialties', []))}ç‰¹è‰² + {len(food.get('restaurants', []))}é¤å… + {len(food.get('streets', []))}ç¾é£Ÿè¡—")
    
    # ä½å®¿
    accommodation = extracted.get("accommodation", {})
    if accommodation:
        areas = accommodation.get("recommended_areas", [])
        print(f"   ğŸ¨ ä½å®¿åŒºåŸŸ: {len(areas)} ä¸ª")
    
    # äº¤é€š
    transportation = extracted.get("transportation", {})
    if transportation:
        print(f"   ğŸš— äº¤é€š: æœ‰")


def _print_plan_summary(plan: dict):
    """æ‰“å°è§„åˆ’ç»“æœæ‘˜è¦"""
    print(f"\nğŸ“‹ è§„åˆ’ç»“æœ:")
    print(f"   ğŸ“ æ¦‚è¿°: {plan.get('overview', '')[:50]}...")
    print(f"   â­ äº®ç‚¹: {plan.get('highlights', [])}")
    print(f"   ğŸ—ºï¸ å‚è€ƒ: {plan.get('reference_routes', [])}")
    
    days = plan.get("days", [])
    print(f"   ğŸ“… è¡Œç¨‹: {len(days)} å¤©")
    
    for day in days:
        day_num = day.get("day", "?")
        theme = day.get("theme", "")
        schedule = day.get("schedule", [])
        print(f"      Day {day_num}: {theme} ({len(schedule)}ä¸ªæ´»åŠ¨)")

# ==================== è¾…åŠ©å‡½æ•° ====================

def _extract_json(content: str) -> str:
    """ä» LLM å“åº”ä¸­æå– JSON å­—ç¬¦ä¸²"""
    if not content:
        return "{}"
    
    content = content.strip()
    
    # æ–¹æ³•1ï¼šæ­£åˆ™åŒ¹é… markdown ä»£ç å—
    pattern = r'```(?:json)?\s*([\s\S]*?)```'
    match = re.search(pattern, content)
    if match:
        return match.group(1).strip()
    
    # æ–¹æ³•2ï¼šæ‰¾ JSON å¯¹è±¡è¾¹ç•Œ
    start = content.find('{')
    end = content.rfind('}')
    
    if start != -1 and end != -1 and end > start:
        return content[start:end + 1]
    
    return content

def _fix_json_string(json_str: str) -> str:
    """
    ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é”™è¯¯
    """
    if not json_str:
        return "{}"
    
    # 1. ç§»é™¤æ³¨é‡Šï¼ˆæŸäº› LLM ä¼šæ·»åŠ æ³¨é‡Šï¼‰
    # ç§»é™¤ // æ³¨é‡Š
    json_str = re.sub(r'//.*?(?=\n|$)', '', json_str)
    # ç§»é™¤ /* */ æ³¨é‡Š
    json_str = re.sub(r'/\*[\s\S]*?\*/', '', json_str)
    
    # 2. ç§»é™¤å°¾éƒ¨é€—å·ï¼ˆå¸¸è§é”™è¯¯ï¼‰
    # ç§»é™¤ },] æˆ– },} å‰çš„é€—å·
    json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
    
    # 3. ä¿®å¤å•å¼•å·ï¼ˆåº”è¯¥æ˜¯åŒå¼•å·ï¼‰
    # è¿™ä¸ªæ¯”è¾ƒå±é™©ï¼Œåªåœ¨è§£æå¤±è´¥æ—¶å°è¯•
    
    # 4. ç§»é™¤æ§åˆ¶å­—ç¬¦
    json_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
    
    # 5. ç¡®ä¿å­—ç¬¦ä¸²ä¸­çš„æ¢è¡Œç¬¦è¢«è½¬ä¹‰
    # è¿™ä¸ªåœ¨ JSON å€¼ä¸­å¾ˆå¸¸è§
    
    return json_str


def _safe_parse_json(content: str, default: dict = None) -> dict:
    """
    å®‰å…¨è§£æ JSONï¼Œå¸¦å¤šé‡å®¹é”™æœºåˆ¶
    
    Args:
        content: åŸå§‹å†…å®¹
        default: è§£æå¤±è´¥æ—¶è¿”å›çš„é»˜è®¤å€¼
        
    Returns:
        è§£æåçš„å­—å…¸
    """
    if default is None:
        default = {}
    
    if not content:
        return default
    
    # å°è¯•1ï¼šæå– JSON åç›´æ¥è§£æ
    try:
        json_str = _extract_json(content)
        return json.loads(json_str)
    except json.JSONDecodeError:
        pass
    
    # å°è¯•2ï¼šä¿®å¤åè§£æ
    try:
        json_str = _extract_json(content)
        fixed = _fix_json_string(json_str)
        return json.loads(fixed)
    except json.JSONDecodeError:
        pass
    
    # å°è¯•3ï¼šä½¿ç”¨æ›´å®½æ¾çš„è§£æï¼ˆå¤„ç†å•å¼•å·ï¼‰
    try:
        json_str = _extract_json(content)
        # æ›¿æ¢å•å¼•å·ä¸ºåŒå¼•å·ï¼ˆå±é™©æ“ä½œï¼Œä»…ä½œä¸ºæœ€åæ‰‹æ®µï¼‰
        fixed = json_str.replace("'", '"')
        return json.loads(fixed)
    except json.JSONDecodeError:
        pass
    
    # å°è¯•4ï¼šé€è¡Œä¿®å¤
    try:
        json_str = _extract_json(content)
        fixed = _fix_json_line_by_line(json_str)
        return json.loads(fixed)
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON è§£ææœ€ç»ˆå¤±è´¥: {e}")
        # æ‰“å°é—®é¢˜ä½ç½®é™„è¿‘çš„å†…å®¹
        _debug_json_error(json_str, e)
    
    return default


def _fix_json_line_by_line(json_str: str) -> str:
    """é€è¡Œä¿®å¤ JSON"""
    lines = json_str.split('\n')
    fixed_lines = []
    
    for i, line in enumerate(lines):
        # ç§»é™¤è¡Œå°¾é€—å·åçš„ç©ºæ ¼å’Œé€—å·ï¼ˆåœ¨ ] æˆ– } ä¹‹å‰ï¼‰
        line = re.sub(r',\s*$', '', line.rstrip())
        
        # å¦‚æœä¸‹ä¸€è¡Œæ˜¯ ] æˆ– }ï¼Œç¡®ä¿å½“å‰è¡Œæ²¡æœ‰é€—å·
        if i < len(lines) - 1:
            next_line = lines[i + 1].strip()
            if next_line.startswith(']') or next_line.startswith('}'):
                line = line.rstrip().rstrip(',')
        
        fixed_lines.append(line)
    
    return '\n'.join(fixed_lines)


def _debug_json_error(json_str: str, error: json.JSONDecodeError):
    """è°ƒè¯• JSON è§£æé”™è¯¯"""
    pos = error.pos
    start = max(0, pos - 100)
    end = min(len(json_str), pos + 100)
    
    context = json_str[start:end]
    pointer_pos = pos - start
    
    print(f"\n{'='*50}")
    print(f"JSON è§£æé”™è¯¯ä½ç½® (å­—ç¬¦ {pos}):")
    print(f"{'='*50}")
    print(context)
    print(' ' * pointer_pos + '^')
    print(f"{'='*50}\n")


def _create_fallback_result(user) -> TravelPlanResult:
    """åˆ›å»ºå…œåº•ç»“æœ"""
    return TravelPlanResult(
    destination=user.destination,
    overview=f"{user.destination}{user.days}å¤©ä¹‹æ—…",
    highlights=[],
    days=[
    {"day": i + 1, "theme": f"ç¬¬{i+1}å¤©", "schedule": []}
    for i in range(user.days)
    ],
    tips={}
    )



def _save_result(state: AgentState) -> Optional[str]:
    """ä¿å­˜ç»“æœï¼Œåˆ›å»ºæ–° plan"""
    from datetime import datetime
    from src.utils.token_budget import TokenBudget
    from src.services.multi_plan_store import multi_plan_store
    
    session_id = state.get("session_id", "")
    if not session_id:
        print("âš ï¸ æ²¡æœ‰ session_idï¼Œæ— æ³•ä¿å­˜")
        return None

    result = state.get("final_result")
    if not result:
        print("âš ï¸ æ²¡æœ‰ final_resultï¼Œæ— æ³•ä¿å­˜")
        return None

    result_dict = result.model_dump() if hasattr(result, 'model_dump') else result
    
    budget = state.get("_token_budget") or TokenBudget()
    route_data = {
        "plan": result_dict,
        "meta": {
            "search_count": state.get("_search_count", 0),
            "token_consumed": budget.get_total_consumed() if hasattr(budget, 'get_total_consumed') else 0,
        },
        "generated_at": datetime.now().isoformat()
    }
    
    # ç”Ÿæˆåç§°
    user = state.get("user_profile")
    plan_name = None
    if user:
        destination = getattr(user, 'destination', '') or result_dict.get('destination', '')
        days = getattr(user, 'days', 0) or len(result_dict.get('days', []))
        if destination:
            plan_name = f"{destination}{days}æ—¥æ¸¸" if days else f"{destination}ä¹‹æ—…"
    
    # ç›´æ¥åˆ›å»ºæ–° plan
    plan_id = multi_plan_store.create_plan(
        session_id=session_id,
        route_data=route_data,
        name=plan_name
    )
    
    if plan_id:
        print(f"ğŸ’¾ å·²ä¿å­˜: {session_id[:8]}.../{plan_id}")
    
    return plan_id



def _print_token_summary(budget: TokenBudget):
    """æ‰“å° Token ç»Ÿè®¡"""
    print(f"\n{'â”€'*40}")
    print(f"ğŸ“Š Token æ¶ˆè€—ç»Ÿè®¡:")
    for stage, tokens in budget.consumed.items():
      print(f" {stage}: {tokens}")
      print(f" â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f" æ€»è®¡: {budget.get_total_consumed()}")
    print(f"{'â”€'*40}")

def create_travel_graph():
    """
    åˆ›å»ºæ—…è¡Œè§„åˆ’å·¥ä½œæµ
    æµç¨‹: search â†’ extract â†’ [check] â†’ plan â†’ END
                  â†‘          â†“
                  â†â”€â”€ need_more
    """
    workflow = StateGraph(AgentState)

    # æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("search", search_node)
    workflow.add_node("extract", extract_node)
    workflow.add_node("plan", plan_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("search")

    # search â†’ extract
    workflow.add_edge("search", "extract")

    # extract â†’ æ£€æŸ¥ â†’ plan æˆ– search
    workflow.add_conditional_edges(
        "extract",
        check_info_quality,
        {
            "need_more": "search",
            "enough": "plan"
        }
    )

    # plan â†’ END
    workflow.add_edge("plan", END)

    return workflow.compile()
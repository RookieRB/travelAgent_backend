# src/agents/chat_agent.py

import os
import json
from datetime import datetime
from typing import Any, Dict, List, Optional, TypedDict, Annotated, Sequence
import operator

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

# å¯¼å…¥å·¥å…·
from src.tools.tools import get_all_tools

from src.models.llm import Myllm

# ============ ç³»ç»Ÿæç¤ºè¯ ============

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—…è¡Œè§„åˆ’åŠ©æ‰‹ï¼Œåå«"å°æ¸¸"ã€‚ä½ çƒ­æƒ…ã€ä¸“ä¸šã€å–„äºå€¾å¬ç”¨æˆ·éœ€æ±‚ã€‚

## ä½ çš„èƒ½åŠ›
1. **æŸ¥è¯¢å¤©æ°”** - ä½¿ç”¨ query_weather å·¥å…·æŸ¥è¯¢ç›®çš„åœ°å¤©æ°”
2. **æœç´¢æ”»ç•¥** - ä½¿ç”¨ search_xiaohongshu å·¥å…·æœç´¢å°çº¢ä¹¦ä¸Šçš„æ—…è¡Œæ”»ç•¥å’ŒçœŸå®ä½“éªŒ
3. **å‘¨è¾¹æœç´¢** - ä½¿ç”¨ search_nearby å·¥å…·æœç´¢å‘¨è¾¹è®¾æ–½
4. **POIæœç´¢** - ä½¿ç”¨ search_poi å·¥å…·æœç´¢å…·ä½“åœ°ç‚¹
5. **è·¯çº¿è§„åˆ’** - ä½¿ç”¨ plan_route å·¥å…·è§„åˆ’äº¤é€šè·¯çº¿
6. **åœ°ç†ç¼–ç ** - ä½¿ç”¨ geo_code å·¥å…·å°†åœ°å€è½¬æ¢ä¸ºåæ ‡
7. **ç”Ÿæˆè®¡åˆ’** - ä½¿ç”¨ generate_travel_plan å·¥å…·ç”Ÿæˆå®Œæ•´çš„æ—…è¡Œè®¡åˆ’

## å·¥ä½œæµç¨‹
1. ä¸»åŠ¨è¯¢é—®ç”¨æˆ·çš„æ—…è¡Œéœ€æ±‚ï¼ˆç›®çš„åœ°ã€å¤©æ•°ã€äººæ•°ã€åå¥½ç­‰ï¼‰
2. æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯åï¼Œä¸»åŠ¨æŸ¥è¯¢ç›®çš„åœ°å¤©æ°”
3. æœç´¢å°çº¢ä¹¦è·å–çœŸå®æ”»ç•¥å’Œé¿å‘æŒ‡å—
4. ç»¼åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆä¸ªæ€§åŒ–æ—…è¡Œè®¡åˆ’

## äº¤äº’åŸåˆ™
- å‹å¥½çƒ­æƒ…ï¼Œåƒæœ‹å‹ä¸€æ ·äº¤æµ
- ä¸»åŠ¨è¯¢é—®ç¼ºå¤±çš„å…³é”®ä¿¡æ¯
- ç”¨ emoji è®©å¯¹è¯æ›´ç”ŸåŠ¨ ğŸ‰âœˆï¸ğŸ–ï¸
- ç»™å‡ºä¸“ä¸šå»ºè®®æ—¶è¯´æ˜ç†ç”±
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œå…ˆè¯¢é—®å†è§„åˆ’

## å…³é”®ä¿¡æ¯æ”¶é›†æ¸…å•
- ç›®çš„åœ° âœˆï¸ï¼ˆå¿…é¡»ï¼‰
- å‡ºè¡Œå¤©æ•° ğŸ“…ï¼ˆå¿…é¡»ï¼‰
- å‡ºå‘åŸå¸‚ ğŸ 
- å‡ºè¡Œæ—¶é—´ â°
- åŒè¡Œäººå‘˜ï¼ˆå®¶åº­/æƒ…ä¾£/æœ‹å‹/ç‹¬è‡ªï¼‰ğŸ‘¥
- åå¥½ï¼ˆç¾é£Ÿ/è´­ç‰©/è‡ªç„¶/å†å²/ç½‘çº¢æ‰“å¡ï¼‰ğŸ’
- é¢„ç®—èŒƒå›´ ğŸ’°

å½“ç”¨æˆ·è¡¨è¾¾æƒ³è¦è§„åˆ’è¡Œç¨‹æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æ”¶é›†äº†ä»¥ä¸Šå…³é”®ä¿¡æ¯ã€‚å¦‚æœç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œå‹å¥½åœ°è¯¢é—®ç”¨æˆ·ã€‚

å½“å‰æ—¶é—´ï¼š{current_time}
"""


class TravelChatAgent:
    """æ—…è¡Œè§„åˆ’å¯¹è¯ Agent"""
    
    def __init__(self, model_name: str = None,travel_graph: Any = None, temperature: float = 0.7):
        """
        åˆå§‹åŒ–å¯¹è¯ Agent
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            temperature: æ¸©åº¦å‚æ•°
        """
 
        self.model_name = os.getenv("OPENAI_MODEL", "qwen-plus")
        self.temperature = temperature
        
        # 1. å…ˆåˆå§‹åŒ–ä¼šè¯å­˜å‚¨ï¼ˆå¿…é¡»åœ¨ _create_agent ä¹‹å‰ï¼‰
        self.memory = MemorySaver()
        
        # 2. åˆå§‹åŒ– LLM
        self.llm = Myllm
        
        # 3. åˆå§‹åŒ–å·¥å…·
        self.tools = get_all_tools(travel_graph)
        
        # 4. æœ€ååˆå§‹åŒ– Agentï¼ˆä¾èµ–ä¸Šé¢çš„æ‰€æœ‰ç»„ä»¶ï¼‰
        self.agent = self._create_agent()
    
    def _create_llm(self) -> ChatOpenAI:
        """åˆ›å»º LLM å®ä¾‹"""
        api_key = os.getenv("OPENAI_API_KEY") 
        base_url = os.getenv("OPENAI_API_BASE")
        if not api_key:
            print("âš ï¸ OPENAI_API_KEY not set, using placeholder")
            api_key = "sk-placeholder"
        
        return ChatOpenAI(
            model=self.model_name,
            temperature=self.temperature,
            api_key=api_key,
            base_url=base_url,
        )
    def _get_system_prompt(self) -> str:
        """è·å–å¸¦å½“å‰æ—¶é—´çš„ç³»ç»Ÿæç¤ºè¯"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return SYSTEM_PROMPT.format(current_time=current_time)
    
    def _create_agent(self):
        """åˆ›å»º ReAct Agent"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),
            MessagesPlaceholder(variable_name="messages"),
        ])
        
        agent = create_react_agent(
            model=self.llm,
            tools=self.tools,
            prompt=prompt,
            checkpointer=self.memory,
        )
        
        return agent
    
    def chat(
        self, 
        message: str, 
        session_id: str = "default",
        stream: bool = False
    ) -> str | Any:
        """
        å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ IDï¼Œç”¨äºä¿æŒå¯¹è¯å†å²
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            AI å›å¤å†…å®¹
        """
        config = {"configurable": {"thread_id": session_id}}
        
        input_message = {"messages": [HumanMessage(content=message)]}
        
        if stream:
            return self._stream_chat(input_message, config)
        else:
            return self._sync_chat(input_message, config)
    
    def _sync_chat(self, input_message: Dict, config: Dict) -> str:
        """åŒæ­¥å¯¹è¯"""
        try:
            result = self.agent.invoke(input_message, config)
            
            # è·å–æœ€åä¸€æ¡ AI æ¶ˆæ¯
            messages = result.get("messages", [])
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    return msg.content
            
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€ï¼Œè¯·å†è¯´ä¸€éï¼Ÿ"
            
        except Exception as e:
            print(f"Chat error: {e}")
            import traceback
            traceback.print_exc()
            return f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†ä¸€äº›é”™è¯¯ï¼š{str(e)}"
    
    def _stream_chat(self, input_message: Dict, config: Dict):
        """æµå¼å¯¹è¯"""
        try:
            for chunk in self.agent.stream(input_message, config, stream_mode="messages"):
                # chunk æ˜¯ (message, metadata) å…ƒç»„
                if isinstance(chunk, tuple):
                    message, metadata = chunk
                    if isinstance(message, AIMessage) and message.content:
                        yield message.content
                elif hasattr(chunk, 'content') and chunk.content:
                    yield chunk.content
                    
        except Exception as e:
            print(f"Stream chat error: {e}")
            import traceback
            traceback.print_exc()
            yield f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†ä¸€äº›é”™è¯¯ï¼š{str(e)}"
    
    async def achat(
        self, 
        message: str, 
        session_id: str = "default",
        stream: bool = False
    ):
        """
        å¼‚æ­¥å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ ID
            stream: æ˜¯å¦æµå¼è¾“å‡º
        """
        config = {"configurable": {"thread_id": session_id}}
        input_message = {"messages": [HumanMessage(content=message)]}
        
        if stream:
            async for chunk in self._astream_chat(input_message, config):
                yield chunk
        else:
            result = await self._async_chat(input_message, config)
            yield result
    
    async def _async_chat(self, input_message: Dict, config: Dict) -> str:
        """å¼‚æ­¥å¯¹è¯"""
        try:
            result = await self.agent.ainvoke(input_message, config)
            
            messages = result.get("messages", [])
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    return msg.content
            
            return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£æ‚¨çš„æ„æ€ï¼Œè¯·å†è¯´ä¸€éï¼Ÿ"
            
        except Exception as e:
            print(f"Async chat error: {e}")
            return f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†ä¸€äº›é”™è¯¯ï¼š{str(e)}"
    
    async def _astream_chat(self, input_message: Dict, config: Dict):
        """å¼‚æ­¥æµå¼å¯¹è¯"""
        try:
            async for chunk in self.agent.astream(input_message, config, stream_mode="messages"):
                if isinstance(chunk, tuple):
                    message, metadata = chunk
                    if isinstance(message, AIMessage) and message.content:
                        yield message.content
                elif hasattr(chunk, 'content') and chunk.content:
                    yield chunk.content
                    
        except Exception as e:
            print(f"Async stream error: {e}")
            yield f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†ä¸€äº›é”™è¯¯ï¼š{str(e)}"
    
    def get_history(self, session_id: str = "default") -> List[Dict]:
        """
        è·å–å¯¹è¯å†å²
        
        Args:
            session_id: ä¼šè¯ ID
            
        Returns:
            å¯¹è¯å†å²åˆ—è¡¨
        """
        try:
            config = {"configurable": {"thread_id": session_id}}
            state = self.agent.get_state(config)
            
            if state and state.values:
                messages = state.values.get("messages", [])
                history = []
                for msg in messages:
                    if isinstance(msg, HumanMessage):
                        history.append({"role": "user", "content": msg.content})
                    elif isinstance(msg, AIMessage):
                        history.append({"role": "assistant", "content": msg.content})
                return history
            
            return []
            
        except Exception as e:
            print(f"Get history error: {e}")
            return []
    
    def clear_history(self, session_id: str = "default"):
        """
        æ¸…é™¤å¯¹è¯å†å²
        
        Args:
            session_id: ä¼šè¯ ID
        """
        try:
            # MemorySaver æ²¡æœ‰ç›´æ¥åˆ é™¤çš„æ–¹æ³•
            # å®é™…é¡¹ç›®ä¸­å¯ä½¿ç”¨æ”¯æŒåˆ é™¤çš„æŒä¹…åŒ–å­˜å‚¨
            print(f"Note: MemorySaver doesn't support clearing. Session: {session_id}")
        except Exception as e:
            print(f"Clear history error: {e}")


# ============ ç®€åŒ–ç‰ˆ Agentï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼Œç”¨äºæµ‹è¯•ï¼‰ ============

class SimpleChatAgent:
    """ç®€åŒ–ç‰ˆå¯¹è¯ Agentï¼Œä¸ä½¿ç”¨å·¥å…·ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=os.getenv("OPENAI_MODEL", "qwen-plus"),
            temperature=0.7,
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_API_BASE"),
        )
        self.history: List[BaseMessage] = []
    
    def chat(self, message: str) -> str:
        """ç®€å•å¯¹è¯"""
        system_msg = SystemMessage(content=SYSTEM_PROMPT.format(
            current_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ))
        
        self.history.append(HumanMessage(content=message))
        
        messages = [system_msg] + self.history
        
        try:
            response = self.llm.invoke(messages)
            self.history.append(response)
            return response.content
        except Exception as e:
            return f"Error: {e}"


# ============ æµ‹è¯•ä»£ç  ============

def test_agent():
    """æµ‹è¯• Agent"""
    print("=" * 60)
    print("Testing TravelChatAgent")
    print("=" * 60)
    
    try:
        agent = TravelChatAgent()
        print("âœ… Agent created successfully")
        print(f"   Model: {agent.model_name}")
        print(f"   Tools: {[t.name for t in agent.tools]}")
        
        # æµ‹è¯•å¯¹è¯
        test_messages = [
            "ä½ å¥½ï¼Œæˆ‘æƒ³å»æ­å·æ—…æ¸¸",
            "å¤§æ¦‚3å¤©æ—¶é—´ï¼Œå’Œå¥³æœ‹å‹ä¸€èµ·",
        ]
        
        session_id = "test_session"
        
        for msg in test_messages:
            print(f"\nğŸ‘¤ User: {msg}")
            response = agent.chat(msg, session_id=session_id)
            print(f"ğŸ¤– Assistant: {response[:200]}..." if len(response) > 200 else f"ğŸ¤– Assistant: {response}")
        
        # æµ‹è¯•è·å–å†å²
        history = agent.get_history(session_id)
        print(f"\nğŸ“œ History length: {len(history)}")
        
        print("\nâœ… All tests passed!")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_agent()
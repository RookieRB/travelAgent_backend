import json
import os
import re
from dotenv import load_dotenv

# Load environment variables FIRST to ensure LLM_MODEL is available
load_dotenv()

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from src.agents.state import AgentState
from src.prompts import (
    XIAOHONGSHU_SUMMARY_PROMPT,
    PLANNING_PROMPT_TEMPLATE,
    AMAP_MCP_CONSTRAINT_PROMPT,
    POLISHING_PROMPT
)
from typing import Optional, List, Dict, Any, Union
from src.models.schemas import SearchResult, SearchNote, PlanningRules, TravelPlanResult

# å¯¼å…¥å·¥å…· - ä»ç»Ÿä¸€çš„ tools æ¨¡å—
from src.tools.tools import (
    XiaohongshuSearchTool,
    RoutePlanTool,
    WeatherTool,
    GeoCodeTool,
)

from src.utils.context import get_session_id
from src.services.redis_service import redis_service
from src.models.llm import Myllm
from datetime import datetime, timedelta
from src.models.schemas import UserProfile
# Initialize LLM
# api_key = os.getenv("OPENAI_API_KEY")
# if not api_key:
#     print("Warning: OPENAI_API_KEY not found in environment. Using dummy key.")
#     api_key = "sk-dummy-key"

# llm = ChatOpenAI(
#     model=os.getenv("LLM_MODEL", "qwen-plus"),
#     temperature=0.7,
#     api_key=api_key,
#     base_url=os.getenv("OPENAI_API_BASE"),
#     timeout=60.0,
#     max_retries=3
# )

llm = Myllm
# src/agents/nodes.py

def generate_search_queries(user_profile: UserProfile, search_count: int, searched_queries: List[str]) -> List[str]:
    """ä½¿ç”¨ LLM æ™ºèƒ½ç”Ÿæˆæœç´¢å…³é”®è¯"""
    
    # âœ… æ ¹æ®ä½ çš„ UserProfile å­—æ®µæ„å»º prompt
    preferences_str = "ã€".join(user_profile.preferences) if user_profile.preferences else "æ— ç‰¹æ®Šåå¥½"
    
    # äººç¾¤ç±»å‹æ˜ å°„
    group_type_map = {
        "solo": "ç‹¬è‡ªæ—…è¡Œ/ç‰¹ç§å…µ",
        "couple": "æƒ…ä¾£/äºŒäººä¸–ç•Œ",
        "family": "äº²å­/å®¶åº­æ¸¸",
        "friends": "æœ‹å‹/é—ºèœœæ¸¸"
    }
    group_desc = group_type_map.get(user_profile.group_type, user_profile.group_type)
    
    prompt = f"""ä½ æ˜¯ä¸€ä½æ—…è¡Œè§„åˆ’åŠ©æ‰‹ï¼Œéœ€è¦åœ¨å°çº¢ä¹¦ä¸Šæœç´¢æ—…è¡Œæ”»ç•¥ã€‚

    ã€ç”¨æˆ·éœ€æ±‚ã€‘
    - å‡ºå‘åœ°: {user_profile.origin}
    - ç›®çš„åœ°: {user_profile.destination}
    - å‡ºè¡Œå¤©æ•°: {user_profile.days}å¤©
    - å‡ºè¡Œæ—¶é—´: {user_profile.date_range or "æœªæŒ‡å®š"}
    - äººç¾¤ç±»å‹: {group_desc}
    - æ—…è¡Œåå¥½: {preferences_str}
    - é¢„ç®—: {user_profile.budget}

    ã€å½“å‰æœç´¢è½®æ¬¡ã€‘ç¬¬ {search_count} è½®

    ã€å·²æœç´¢è¿‡çš„å…³é”®è¯ã€‘ï¼ˆè¯·å‹¿é‡å¤ï¼‰
    {json.dumps(searched_queries, ensure_ascii=False) if searched_queries else "æ— "}

    ã€ä»»åŠ¡ã€‘
    ç”Ÿæˆ 2-3 ä¸ªæœ€æœ‰ä»·å€¼çš„å°çº¢ä¹¦æœç´¢å…³é”®è¯ï¼Œç”¨äºè·å–æ—…è¡Œæ”»ç•¥ã€‚

    ã€è¦æ±‚ã€‘
    1. å…³é”®è¯è¦å…·ä½“ã€ç¬¦åˆå°çº¢ä¹¦æœç´¢ä¹ æƒ¯
    2. å¿…é¡»ç»“åˆç”¨æˆ·çš„äººç¾¤ç±»å‹å’Œåå¥½
    3. ä¸è¦ä¸å·²æœç´¢çš„å…³é”®è¯é‡å¤æˆ–ç›¸ä¼¼
    4. æœç´¢ç­–ç•¥ï¼š
    - ç¬¬1è½®ï¼šä¼˜å…ˆæœç´¢è·¯çº¿è§„åˆ’ã€å¿…å»æ™¯ç‚¹
    - ç¬¬2è½®ï¼šä¼˜å…ˆæœç´¢é¿å‘æ”»ç•¥ã€ç¾é£Ÿä½å®¿
    - åç»­ï¼šå°ä¼—æ¨èã€çœé’±æŠ€å·§ã€ç‰¹æ®Šéœ€æ±‚

    ã€å…³é”®è¯ç”ŸæˆæŠ€å·§ã€‘
    - å¦‚æœæ˜¯"ç‰¹ç§å…µ"åå¥½ï¼ŒåŠ å…¥"ä¸€æ—¥æ¸¸"ã€"æš´èµ°"ã€"é«˜æ•ˆ"ç­‰è¯
    - å¦‚æœæ˜¯"ç¾é£Ÿ"åå¥½ï¼ŒåŠ å…¥"å¿…åƒ"ã€"æœ¬åœ°äººæ¨è"ç­‰è¯
    - å¦‚æœæ˜¯"æ‹ç…§"åï¿½ï¿½ï¼ŒåŠ å…¥"æ‰“å¡"ã€"å‡ºç‰‡"ã€"ç½‘çº¢"ç­‰è¯
    - å¦‚æœæ˜¯"äº²å­"ç±»å‹ï¼ŒåŠ å…¥"å¸¦å¨ƒ"ã€"é›å¨ƒ"ã€"å„¿ç«¥å‹å¥½"ç­‰è¯
    - å¦‚æœæ˜¯"æƒ…ä¾£"ç±»å‹ï¼ŒåŠ å…¥"çº¦ä¼š"ã€"æµªæ¼«"ã€"äºŒäººæ¸¸"ç­‰è¯

    ã€è¾“å‡ºæ ¼å¼ã€‘
    ç›´æ¥è¾“å‡ºå…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·æˆ–å…¶ä»–å¤šä½™å†…å®¹ï¼š
    å…³é”®è¯1
    å…³é”®è¯2
    å…³é”®è¯3
    """

    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        
        # è§£æå…³é”®è¯
        lines = response.content.strip().split("\n")
        queries = []
        for line in lines:
            line = line.strip()
            # è¿‡æ»¤ç©ºè¡Œå’Œæ ¼å¼å­—ç¬¦
            if not line or line.startswith(("-", "*", "â€¢", "#", "ã€")):
                continue
            # ç§»é™¤å¯èƒ½çš„ç¼–å· (1. 2. ç­‰)
            if len(line) > 2 and line[0].isdigit() and line[1] in ".ã€):ï¼š":
                line = line[2:].strip()
            if len(line) > 2:
                queries.append(line)
        
        # è¿‡æ»¤å·²æœç´¢è¿‡çš„
        queries = [q for q in queries if q not in searched_queries]
        
        print(f"ğŸ¤– LLM ç”Ÿæˆçš„æœç´¢å…³é”®è¯: {queries}")
        
        return queries[:3]  # æœ€å¤šè¿”å›3ä¸ª
        
    except Exception as e:
        print(f"âš ï¸ LLM ç”Ÿæˆå…³é”®è¯å¤±è´¥: {e}ï¼Œä½¿ç”¨å…œåº•å…³é”®è¯")
        # å…œåº•å…³é”®è¯
        fallback = [
            f"{user_profile.destination} {user_profile.days}å¤©æ”»ç•¥",
            f"{user_profile.destination} å¿…å»æ™¯ç‚¹"
        ]
        return [q for q in fallback if q not in searched_queries][:2]

def search_node(state: AgentState) -> AgentState:
    """æœç´¢èŠ‚ç‚¹ - ä½¿ç”¨å°çº¢ä¹¦MCPæœç´¢æ”»ç•¥"""
    search_count = state.get("_search_count", 1)
    print(f"--- SEARCH AGENT (ç¬¬ {search_count} æ¬¡æœç´¢) ---")
    
    # âœ… ä¿ç•™ session_id
    session_id = state.get("session_id", "")
    print(f"ğŸ“Œ Search Node session_id: {session_id}")

    user_profile = state["user_profile"]
    destination = user_profile.destination
    
    # è·å–å·²æœç´¢çš„å…³é”®è¯
    searched_queries = state.get("_search_queries", [])
    
    # âœ… ä½¿ç”¨ LLM æ™ºèƒ½ç”Ÿæˆæœç´¢å…³é”®è¯
    queries = generate_search_queries(user_profile, search_count, searched_queries)
    
    if not queries:
        print("âš ï¸ æ²¡æœ‰æ–°çš„æœç´¢å…³é”®è¯")
        return state
    
    # ä½¿ç”¨å°çº¢ä¹¦æœç´¢å·¥å…·
    search_tool = XiaohongshuSearchTool()
    
    # è·å–ç°æœ‰çš„ç¬”è®°
    existing_notes = []
    if state.get("search_results"):
        existing_notes = state["search_results"].notes or []
    
    notes = list(existing_notes)  # å¤åˆ¶ç°æœ‰ç¬”è®°
    
    for q in queries:
        try:
            print(f"ğŸ” æœç´¢: {q}")
            res = search_tool._run(keyword=q)
            data = json.loads(res)
            
            if "error" in data:
                print(f"âŒ æœç´¢å¤±è´¥ {q}: {data['error']}")
                continue
            
            # æå–ç¬”è®°å†…å®¹
            content_parts = []
            for note in data.get("notes", []):
                title = note.get("title", "æ— æ ‡é¢˜")
                desc = note.get("desc", "")
                author = note.get("author", "æœªçŸ¥")
                likes = note.get("likes", 0)
                
                if desc:
                    note_text = f"""
                    ğŸ“ ã€{title}ã€‘
                    ğŸ‘¤ ä½œè€…: {author} | ğŸ‘ ç‚¹èµ: {likes}
                    ğŸ“– å†…å®¹:
                    {desc}
                    """
                    content_parts.append(note_text)
            
            if content_parts:
                combined_content = "\n" + "="*50 + "\n".join(content_parts)
                notes.append(SearchNote(title=q, content=combined_content[:4000]))
                print(f"âœ… è·å–åˆ° {len(content_parts)} ç¯‡ç¬”è®°")
            
            # è®°å½•å·²æœç´¢çš„å…³é”®è¯
            searched_queries.append(q)
                
        except Exception as e:
            print(f"âŒ æœç´¢å¼‚å¸¸ {q}: {e}")
    
    state["search_results"] = SearchResult(notes=notes)
    state["_search_queries"] = searched_queries
    print(f"ğŸ“Š æœç´¢å®Œæˆï¼Œç´¯è®¡ {len(notes)} ç»„ç»“æœ")
    
    return state


# def search_node(state: AgentState) -> AgentState:
#     """æœç´¢èŠ‚ç‚¹ - ä½¿ç”¨å°çº¢ä¹¦MCPæœç´¢æ”»ç•¥"""
#     search_count = state.get("_search_count", 1)
#     print(f"--- SEARCH AGENT (ç¬¬ {search_count} æ¬¡æœç´¢) ---")
    
#      # âœ… ä¿ç•™ session_id
#     session_id = state.get("session_id", "")
#     print(f"ğŸ“Œ Search Node session_id: {session_id}")

#     user_profile = state["user_profile"]
#     destination = user_profile.destination
    
#     # è·å–å·²æœç´¢çš„å…³é”®è¯
#     searched_queries = state.get("_search_queries", [])
    
#     # ä½¿ç”¨å°çº¢ä¹¦æœç´¢å·¥å…·
#     search_tool = XiaohongshuSearchTool()
    
#     # âœ… æ ¹æ®æœç´¢æ¬¡æ•°ä½¿ç”¨ä¸åŒçš„å…³é”®è¯
#     if search_count == 1:
#         queries = [
#             f"{destination} {user_profile.days}å¤©æ¸¸ç©è·¯çº¿",
#             f"{destination} å¿…å»æ™¯ç‚¹æ¨è",
#         ]
#     elif search_count == 2:
#         queries = [
#             f"{destination} é¿å‘æ”»ç•¥",
#             f"{destination} ç¾é£Ÿæ¨è",
#         ]
#     else:
#         queries = [
#             f"{destination} å°ä¼—æ™¯ç‚¹",
#             f"{destination} äº¤é€šæ”»ç•¥",
#         ]
    
#     # è¿‡æ»¤å·²æœç´¢è¿‡çš„
#     queries = [q for q in queries if q not in searched_queries]
    
#     if not queries:
#         print("âš ï¸ æ²¡æœ‰æ–°çš„æœç´¢å…³é”®è¯")
#         return state
    
#     # è·å–ç°æœ‰çš„ç¬”è®°
#     existing_notes = []
#     if state.get("search_results"):
#         existing_notes = state["search_results"].notes or []
    
#     notes = list(existing_notes)  # å¤åˆ¶ç°æœ‰ç¬”è®°
    
#     for q in queries:
#         try:
#             print(f"ğŸ” æœç´¢: {q}")
#             res = search_tool._run(keyword=q)
#             data = json.loads(res)
            
#             if "error" in data:
#                 print(f"âŒ æœç´¢å¤±è´¥ {q}: {data['error']}")
#                 continue
            
#             # æå–ç¬”è®°å†…å®¹
#             content_parts = []
#             for note in data.get("notes", []):
#                 title = note.get("title", "æ— æ ‡é¢˜")
#                 desc = note.get("desc", "")
#                 author = note.get("author", "æœªçŸ¥")
#                 likes = note.get("likes", 0)
                
#                 if desc:
#                     note_text = f"""
#                     ğŸ“ ã€{title}ã€‘
#                     ğŸ‘¤ ä½œè€…: {author} | ğŸ‘ ç‚¹èµ: {likes}
#                     ğŸ“– å†…å®¹:
#                     {desc}
#                     """
#                     content_parts.append(note_text)
            
#             if content_parts:
#                 combined_content = "\n" + "="*50 + "\n".join(content_parts)
#                 notes.append(SearchNote(title=q, content=combined_content[:4000]))
#                 print(f"âœ… è·å–åˆ° {len(content_parts)} ç¯‡ç¬”è®°")
            
#             # è®°å½•å·²æœç´¢çš„å…³é”®è¯
#             searched_queries.append(q)
                
#         except Exception as e:
#             print(f"âŒ æœç´¢å¼‚å¸¸ {q}: {e}")
    
#     state["search_results"] = SearchResult(notes=notes)
#     state["_search_queries"] = searched_queries
#     print(f"ğŸ“Š æœç´¢å®Œæˆï¼Œç´¯è®¡ {len(notes)} ç»„ç»“æœ")
    
#     return state

def summary_node(state: AgentState) -> AgentState:
    """æ€»ç»“èŠ‚ç‚¹ - æ•´ç†æœç´¢ç»“æœä¸ºè§„åˆ’è§„åˆ™"""
    print("--- SUMMARY AGENT ---")
    search_results = state.get("search_results")
    
    if not search_results or not search_results.notes:
        print("âš ï¸ æ²¡æœ‰æœç´¢ç»“æœå¯ä¾›æ€»ç»“")
        state["planning_rules"] = create_default_rules(
            state.get("user_profile").destination if state.get("user_profile") else ""
        )
        return state
    
    print(f"ğŸ“š å…±æœ‰ {len(search_results.notes)} æ¡ç¬”è®°å¾…æ€»ç»“")
    
    # Combine notes into context
    context = "\n\n".join([
        f"ã€ç¬”è®°{i+1}ã€‘\næ ‡é¢˜: {n.title}\nå†…å®¹: {n.content}\nç‚¹èµ: {n.likes or 0}" 
        for i, n in enumerate(search_results.notes)
    ])
    
    prompt = f"{XIAOHONGSHU_SUMMARY_PROMPT}\n\nã€æœç´¢ç»“æœã€‘\n{context}"
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    # âœ… è°ƒè¯•ï¼šæ‰“å° LLM åŸå§‹å“åº”
    print("\n" + "=" * 60)
    print("ğŸ” SUMMARY LLM åŸå§‹å“åº”ï¼š")
    print("=" * 60)
    print(response.content[:2000])  # åªæ‰“å°å‰2000å­—ç¬¦
    if len(response.content) > 2000:
        print(f"\n... è¿˜æœ‰ {len(response.content) - 2000} å­—ç¬¦ ...")
    print("=" * 60 + "\n")
    
    try:
        # Extract JSON from markdown code block if present
        content = response.content.strip()
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
        
        content = content.strip()
        
        # âœ… è°ƒè¯•ï¼šæ‰“å°æå–çš„ JSON
        print("ğŸ“‹ æå–çš„ JSON å†…å®¹ï¼š")
        print(content[:1500])
        if len(content) > 1500:
            print(f"\n... è¿˜æœ‰ {len(content) - 1500} å­—ç¬¦ ...")
        print()
        
        data = json.loads(content)
        
        # âœ… è°ƒè¯•ï¼šæ‰“å°è§£æåçš„ç»“æ„
        print("ğŸ“Š è§£æåçš„ JSON é”®ï¼š", list(data.keys()))
        
        # âœ… æ•°æ®é¢„å¤„ç†ï¼šä¿®å¤ç±»å‹é—®é¢˜
        data = normalize_planning_rules_data(data)
        
        rules = PlanningRules(**data)
        state["planning_rules"] = rules
        
        # âœ… æ‰“å°æ€»ç»“ç»“æœ
        print("\n" + "=" * 60)
        print("âœ… SUMMARY ç»“æœï¼š")
        print("=" * 60)
        print(f"ğŸ“ ç›®çš„åœ°: {rules.destination}")
        print(f"ğŸ“… æ¨èå¤©æ•°: {rules.get_recommended_days_str()}")
        print(f"ğŸ—ºï¸ æ¯æ—¥è·¯çº¿æ•°: {len(rules.daily_routes)}")
        print(f"â­ å¿…å»æ™¯ç‚¹: {rules.get_must_visit_names()[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"âš ï¸ é¿å‘å»ºè®®: {rules.get_avoid_list()[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ª
        print(f"ğŸš— äº¤é€šå»ºè®®: {rules.transport_tips[:2]}...")  # åªæ˜¾ç¤ºå‰2ä¸ª
        print(f"ğŸ“ å®ç”¨è´´å£«: {rules.practical_tips[:2]}...")
        print("=" * 60 + "\n")
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        print(f"   é”™è¯¯ä½ç½®: ç¬¬ {e.lineno} è¡Œ, ç¬¬ {e.colno} åˆ—")
        state["planning_rules"] = create_default_rules(
            state.get("user_profile").destination if state.get("user_profile") else ""
        )
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {type(e).__name__}: {e}. Using fallback.")
        import traceback
        traceback.print_exc()
        state["planning_rules"] = create_default_rules(
            state.get("user_profile").destination if state.get("user_profile") else ""
        )
        
    return state

def normalize_planning_rules_data(data: dict) -> dict:
    """æ ‡å‡†åŒ–è§„åˆ’è§„åˆ™æ•°æ®ï¼Œä¿®å¤ç±»å‹é—®é¢˜"""
    
    # 1. ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨
    data.setdefault("destination", "")
    data.setdefault("recommended_days", "")
    data.setdefault("daily_routes", [])
    data.setdefault("common_routes", [])
    data.setdefault("must_visit", [])
    data.setdefault("avoid_list", [])
    data.setdefault("avoid", [])
    data.setdefault("transport_tips", [])
    data.setdefault("practical_tips", [])
    
    # 2. âœ… ä¿®å¤ recommended_days ç±»å‹é—®é¢˜
    if isinstance(data.get("recommended_days"), int):
        data["recommended_days"] = f"{data['recommended_days']}å¤©"
    elif data.get("recommended_days") is None:
        data["recommended_days"] = ""
    
    # 3. ä» daily_routes ç”Ÿæˆ common_routesï¼ˆå¦‚æœä¸ºç©ºï¼‰
    if data.get("daily_routes") and not data.get("common_routes"):
        routes = []
        for route in data["daily_routes"]:
            if isinstance(route, dict):
                day = route.get("day", "")
                theme = route.get("theme", "")
                schedule = route.get("schedule", [])
                if schedule:
                    places = []
                    for s in schedule:
                        if isinstance(s, dict):
                            places.append(s.get("place", s.get("name", "")))
                    if places:
                        route_str = f"Day{day} {theme}: {' -> '.join(filter(None, places))}"
                        routes.append(route_str)
        data["common_routes"] = routes
    
    # 4. ä» avoid_list ç”Ÿæˆ avoidï¼ˆå¦‚æœä¸ºç©ºï¼‰
    if data.get("avoid_list") and not data.get("avoid"):
        avoid_strs = []
        for item in data["avoid_list"]:
            if isinstance(item, str):
                avoid_strs.append(item)
            elif isinstance(item, dict):
                item_text = item.get("item", "")
                reason = item.get("reason", "")
                if item_text:
                    if reason:
                        avoid_strs.append(f"{item_text}ï¼ˆ{reason}ï¼‰")
                    else:
                        avoid_strs.append(item_text)
        data["avoid"] = avoid_strs
    
    # 5. ç¡®ä¿åˆ—è¡¨å­—æ®µæ˜¯åˆ—è¡¨
    list_fields = ["transport_tips", "practical_tips", "common_routes"]
    for field in list_fields:
        if isinstance(data.get(field), str):
            data[field] = [data[field]] if data[field] else []
    
    # 6. âœ…âœ…âœ… å¤„ç† food_accommodationï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
    if data.get("food_accommodation") is None:
        data["food_accommodation"] = {
            "food_areas": [],
            "stay_areas": [],
            "recommendations": []
        }
    elif isinstance(data["food_accommodation"], dict):
        fa = data["food_accommodation"]
        fa.setdefault("food_areas", [])
        fa.setdefault("stay_areas", [])
        fa.setdefault("recommendations", [])
        
        # âœ… å…³é”®ä¿®å¤ï¼šå°† recommendations ä¸­çš„å­—å…¸è½¬ä¸ºå­—ç¬¦ä¸²
        if isinstance(fa.get("recommendations"), list):
            normalized_recs = []
            for item in fa["recommendations"]:
                if isinstance(item, str):
                    normalized_recs.append(item)
                elif isinstance(item, dict):
                    # æ ¼å¼1: {"name": "é¸­è¡€ç²‰ä¸æ±¤", "place": "å—äº¬è€å­—å·"}
                    if "name" in item:
                        name = item.get("name", "")
                        place = item.get("place", "")
                        if place:
                            normalized_recs.append(f"{name} - {place}")
                        else:
                            normalized_recs.append(name)
                    # æ ¼å¼2: {"ä½å®¿æ¨è": "å¦‚å®¶é…’åº—ã€æ±‰åº­é…’åº—ç­‰"}
                    else:
                        for k, v in item.items():
                            normalized_recs.append(f"{k}: {v}")
                else:
                    normalized_recs.append(str(item))
            fa["recommendations"] = normalized_recs
        
        # âœ… åŒæ ·ç¡®ä¿ food_areas å’Œ stay_areas æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
        for field in ["food_areas", "stay_areas"]:
            if isinstance(fa.get(field), list):
                fa[field] = [str(x) if not isinstance(x, str) else x for x in fa[field]]
    
    # 7. å¤„ç† crowd_specific
    if data.get("crowd_specific") is None:
        data["crowd_specific"] = {
            "family": [],
            "couple": [],
            "friends": [],
            "solo": []
        }
    elif isinstance(data["crowd_specific"], dict):
        cs = data["crowd_specific"]
        for field in ["family", "couple", "friends", "solo"]:
            cs.setdefault(field, [])
            # âœ… ç¡®ä¿æ¯ä¸ªå­—æ®µéƒ½æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            if isinstance(cs.get(field), list):
                cs[field] = [str(x) if not isinstance(x, str) else x for x in cs[field]]
    
    # 8. âœ… æ–°å¢ï¼šå¤„ç† must_visitï¼ˆç¡®ä¿æ ¼å¼æ­£ç¡®ï¼‰
    if isinstance(data.get("must_visit"), list):
        normalized_must_visit = []
        for item in data["must_visit"]:
            if isinstance(item, str):
                normalized_must_visit.append({
                    "name": item,
                    "reason": "",
                    "best_time": "",
                    "duration": ""
                })
            elif isinstance(item, dict):
                normalized_must_visit.append({
                    "name": item.get("name", item.get("æ™¯ç‚¹", "")),
                    "reason": item.get("reason", item.get("æ¨èç†ç”±", "")),
                    "best_time": item.get("best_time", item.get("æœ€ä½³æ—¶é—´", "")),
                    "duration": item.get("duration", item.get("å»ºè®®æ—¶é•¿", ""))
                })
        data["must_visit"] = normalized_must_visit
    
    # 9. âœ… æ–°å¢ï¼šå¤„ç† avoid_listï¼ˆç¡®ä¿æ ¼å¼æ­£ç¡®ï¼‰
    if isinstance(data.get("avoid_list"), list):
        normalized_avoid = []
        for item in data["avoid_list"]:
            if isinstance(item, str):
                normalized_avoid.append({
                    "item": item,
                    "reason": ""
                })
            elif isinstance(item, dict):
                normalized_avoid.append({
                    "item": item.get("item", item.get("é¿å‘é¡¹", str(item))),
                    "reason": item.get("reason", item.get("åŸå› ", ""))
                })
        data["avoid_list"] = normalized_avoid
    
    return data

def create_default_rules(destination: str = "") -> PlanningRules:
    """åˆ›å»ºé»˜è®¤è§„åˆ’è§„åˆ™"""
    return PlanningRules(
        destination=destination,
        recommended_days="3å¤©",
        daily_routes=[],
        common_routes=[],
        must_visit=[],
        avoid_list=[],
        avoid=["èŠ‚å‡æ—¥çƒ­é—¨æ™¯ç‚¹äººå¤š", "é«˜å³°æœŸæ‰“è½¦éš¾"],
        transport_tips=["å»ºè®®ä½¿ç”¨å…¬å…±äº¤é€š", "æå‰è§„åˆ’è·¯çº¿"],
        practical_tips=["æå‰é¢„çº¦çƒ­é—¨æ™¯ç‚¹", "æ³¨æ„å¤©æ°”å˜åŒ–"],
        sources_summary="ä½¿ç”¨é»˜è®¤è§„åˆ™"
    )

def planning_node(state: AgentState) -> AgentState:
    """è§„åˆ’èŠ‚ç‚¹ - ç”Ÿæˆè¡Œç¨‹è‰æ¡ˆ"""
    print("--- PLANNING AGENT ---")
    user = state["user_profile"]
    rules = state.get("planning_rules")
    
    # å¦‚æœæ²¡æœ‰è§„åˆ™ï¼Œåˆ›å»ºé»˜è®¤è§„åˆ™
    if not rules:
        print("âš ï¸ æ²¡æœ‰è§„åˆ’è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™")
        rules = PlanningRules(
            common_routes=[],
            must_visit=[],
            avoid=[],
            transport_tips=[]
        )
    
    # âœ… å…ˆåºåˆ—åŒ–è§„åˆ™
    try:
        rules_str = rules.model_dump_json(ensure_ascii=False)
    except Exception:
        rules_str = "æŒ‰ç…§é€šç”¨æ—…è¡Œè§„åˆ’åŸåˆ™è¿›è¡Œå®‰æ’"
    
    # âœ… Format the planning prompt - æ·»åŠ  planning_rules å‚æ•°ï¼
    prompt = PLANNING_PROMPT_TEMPLATE.format(
        origin=user.origin,
        destination=user.destination,
        days=user.days,
        date_range=user.date_range or "ä¸é™",
        group_type=user.group_type,
        preferences=", ".join(user.preferences) if user.preferences else "æ— ç‰¹æ®Šåå¥½",
        budget=user.budget or "ä¸é™",
        planning_rules=rules_str  # âœ…âœ…âœ… æ·»åŠ è¿™ä¸€è¡Œï¼
    )
    
    # æ·»åŠ å¤©æ°”ä¿¡æ¯
    weather_context = ""
    weather_info = state.get("weather_info")
    if weather_info:
        weather_context = f"\n\nå¤©æ°”ä¿¡æ¯ï¼š{json.dumps(weather_info, ensure_ascii=False)}"
    
    response = llm.invoke([
        SystemMessage(content=prompt),
        HumanMessage(content=f"è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆè¯¦ç»†è¡Œç¨‹{weather_context}")
    ])
    
    # Ask LLM to structure the plan as JSON
    structure_prompt = "è¯·å°†ä»¥ä¸Šè¡Œç¨‹è½¬æ¢ä¸º JSON æ ¼å¼ï¼ŒåŒ…å« days æ•°ç»„ï¼Œæ¯å¤©æœ‰ schedule åˆ—è¡¨ã€‚"
    
    json_res = llm.invoke([
        SystemMessage(content=prompt),
        HumanMessage(content=f"è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆè¯¦ç»†è¡Œç¨‹{weather_context}"),
        HumanMessage(content=response.content),
        HumanMessage(content=structure_prompt)
    ])
    
    try:
        content = json_res.content.strip()
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
        
        plan_dict = json.loads(content)
        print(plan_dict)
        state["draft_plan"] = plan_dict
        print("âœ… è¡Œç¨‹è‰æ¡ˆç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        state["draft_plan"] = {"error": "Failed to parse plan", "raw": response.content}
        
    return state

def map_node(state: AgentState) -> AgentState:
    """åœ°å›¾èŠ‚ç‚¹ - ä½¿ç”¨é«˜å¾·MCPéªŒè¯è·¯çº¿"""
    print("--- MAP AGENT ---")
    plan = state["draft_plan"]
    
    if "days" not in plan:
        print("âš ï¸ è¡Œç¨‹æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡åœ°å›¾éªŒè¯")
        state["validated_plan"] = plan
        return state
    
    # ä½¿ç”¨æ–°çš„è·¯çº¿è§„åˆ’å·¥å…·
    route_tool = RoutePlanTool()
    validated_days = []
    mcp_available = True
    
    for day_idx, day in enumerate(plan["days"]):
        schedule = day.get("schedule", [])
        new_schedule = []
        
        print(f"ğŸ“ å¤„ç†ç¬¬ {day_idx + 1} å¤©è¡Œç¨‹...")
        
        for i in range(len(schedule) - 1):
            curr = schedule[i]
            next_spot = schedule[i + 1]
            
            curr_poi = curr.get("poi", curr.get("name", curr.get("location", "")))
            next_poi = next_spot.get("poi", next_spot.get("name", next_spot.get("location", "")))
            
            if curr_poi and next_poi and mcp_available:
                try:
                    route_info = route_tool._run(
                        origin=curr_poi,
                        destination=next_poi,
                        mode="driving"
                    )
                    route_data = json.loads(route_info)
                    
                    if "error" not in route_data:
                        distance = route_data.get("distance", "æœªçŸ¥")
                        duration = route_data.get("duration", "æœªçŸ¥")
                        curr["transport_suggestion"] = f"åˆ°ä¸‹ä¸€ç«™: {distance}, çº¦ {duration}"
                        print(f"  âœ… {curr_poi} â†’ {next_poi}: {distance}, {duration}")
                    else:
                        curr["transport_suggestion"] = "è·¯çº¿ä¿¡æ¯è·å–å¤±è´¥"
                        print(f"  âš ï¸ {curr_poi} â†’ {next_poi}: {route_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except json.JSONDecodeError:
                    curr["transport_suggestion"] = "è·¯çº¿è§£æå¤±è´¥"
                except Exception as e:
                    print(f"  âŒ è·¯çº¿è§„åˆ’å¼‚å¸¸: {type(e).__name__}: {e}")
                    curr["transport_suggestion"] = "è·¯çº¿ä¿¡æ¯æš‚ä¸å¯ç”¨"
                    
                    # å¦‚æœæ˜¯è¶…æ—¶é”™è¯¯ï¼Œåç»­ä¸å†å°è¯•
                    if "Timeout" in type(e).__name__ or "è¶…æ—¶" in str(e):
                        print("  âš ï¸ æ£€æµ‹åˆ°è¶…æ—¶ï¼Œè·³è¿‡åç»­è·¯çº¿æŸ¥è¯¢")
                        mcp_available = False
            
            new_schedule.append(curr)
            
            # å¦‚æœ MCP ä¸å¯ç”¨ï¼Œç›´æ¥å¤åˆ¶å‰©ä½™è¡Œç¨‹
            if not mcp_available:
                new_schedule.extend(schedule[i+1:])
                break
        else:
            # æ­£å¸¸ç»“æŸå¾ªç¯ï¼Œæ·»åŠ æœ€åä¸€ä¸ªæ™¯ç‚¹
            if schedule:
                new_schedule.append(schedule[-1])
        
        day["schedule"] = new_schedule
        validated_days.append(day)
    
    plan["days"] = validated_days
    state["validated_plan"] = plan
    print("âœ… åœ°å›¾éªŒè¯å®Œæˆ")
    return state

def weather_node(state: AgentState) -> AgentState:
    """å¤©æ°”èŠ‚ç‚¹ - æŸ¥è¯¢ç›®çš„åœ°å¤©æ°”ï¼ˆå¯é€‰ï¼‰"""
    print("--- WEATHER AGENT ---")
    user_profile = state["user_profile"]
    destination = user_profile.destination
    
    weather_tool = WeatherTool()
    
    try:
        result = weather_tool._run(city=destination)
        weather_data = json.loads(result)
        
        if "error" not in weather_data:
            state["weather_info"] = weather_data
            print(f"âœ… è·å– {destination} å¤©æ°”æˆåŠŸ")
            
            # å°†å¤©æ°”å»ºè®®æ·»åŠ åˆ°è§„åˆ’è§„åˆ™
            if state.get("planning_rules") and weather_data.get("travel_tips"):
                tips = state["planning_rules"].transport_tips or []
                tips.extend(weather_data["travel_tips"])
                state["planning_rules"].transport_tips = tips
        else:
            print(f"âš ï¸ å¤©æ°”æŸ¥è¯¢å¤±è´¥: {weather_data.get('error')}")
            
    except Exception as e:
        print(f"âŒ å¤©æ°”æŸ¥è¯¢å¼‚å¸¸: {e}")
    
    return state


def refine_node(state: AgentState) -> AgentState:
    """ç²¾ç‚¼èŠ‚ç‚¹ - æ¶¦è‰²æœ€ç»ˆè¡Œç¨‹"""
    print("--- REFINE AGENT ---")
    
    # âœ… è°ƒè¯•ï¼šæ‰“å° state çš„æ‰€æœ‰ key
    print(f"ğŸ“‹ State keys: {list(state.keys())}")
    
    # âœ… è·å– session_id
    session_id = state.get("session_id") or get_session_id()
    print(f"ğŸ“Œ state.get('session_id'): '{state.get('session_id')}'")
    print(f"ğŸ“Œ get_session_id(): '{get_session_id()}'")
    print(f"ğŸ“Œ Final session_id: '{session_id}'")
    
    # æ›´æ–°è¿›åº¦
    if session_id:
        redis_service.update_plan_status(
            session_id,
            status="processing",
            progress=80,
            message="æ­£åœ¨æ¶¦è‰²è¡Œç¨‹..."
        )

    plan = state.get("validated_plan") or state.get("draft_plan")
    user_profile = state.get("user_profile")
    
    destination = user_profile.destination if user_profile else "ç›®çš„åœ°"
    days_count = user_profile.days if user_profile else 3
    
    if not plan:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„è¡Œç¨‹æ•°æ®")
        state["final_result"] = create_empty_result(destination, days_count)
        _save_to_cache(state)
        return state
    
    # æ·»åŠ å¤©æ°”ä¿¡æ¯
    weather_context = ""
    if state.get("weather_info"):
        weather_info = state["weather_info"]
        weather_context = f"\n\nå½“å‰å¤©æ°”ä¿¡æ¯ï¼š\n{json.dumps(weather_info, ensure_ascii=False)}"
    
    content = json.dumps(plan, ensure_ascii=False)
    
      # æ›´æ–°è¿›åº¦
    if session_id:
        redis_service.update_plan_status(
            session_id,
            status="processing",
            progress=85,
            message="æ­£åœ¨ç”Ÿæˆæœ€ç»ˆè®¡åˆ’..."
        )


    response = llm.invoke([
        SystemMessage(content=POLISHING_PROMPT),
        HumanMessage(content=f"{content}{weather_context}")
    ])
    
    try:
        res_content = response.content.strip()
        
        # æå– JSON
        if "```json" in res_content:
            res_content = res_content.split("```json")[1].split("```")[0]
        elif "```" in res_content:
            res_content = res_content.split("```")[1].split("```")[0]
        
        res_content = res_content.strip()
        res_content = fix_json_string(res_content)
        
        final_json = json.loads(res_content)
        
        # æ ‡å‡†åŒ–æ•°æ®
        normalized = normalize_plan_data(final_json, destination)
        state["final_result"] = TravelPlanResult(**normalized)
        
        # âœ… å­˜å‚¨åˆ°ç¼“å­˜
        _save_to_cache(state)
        
        print("âœ… è¡Œç¨‹æ¶¦è‰²å®Œæˆ")
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        state["final_result"] = create_fallback_result(state, plan, destination, days_count)
        _save_to_cache(state)
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        state["final_result"] = create_fallback_result(state, plan, destination, days_count)
        _save_to_cache(state)
        
    return state

def fix_json_string(json_str: str) -> str:
    """ä¿®å¤ JSON å­—ç¬¦ä¸²ä¸­çš„å¸¸è§é—®é¢˜"""
    
    # 1. ä¿®å¤å­—ç¬¦ä¸²å†…éƒ¨çš„æ¢è¡Œç¬¦ï¼ˆåœ¨å¼•å·å†…çš„æ¢è¡Œè½¬ä¸ºç©ºæ ¼ï¼‰
    # åŒ¹é… "..." å†…çš„å†…å®¹ï¼Œæ›¿æ¢å…¶ä¸­çš„æ¢è¡Œ
    def fix_string_newlines(match):
        content = match.group(0)
        # æ›¿æ¢å­—ç¬¦ä¸²å†…çš„å®é™…æ¢è¡Œä¸ºç©ºæ ¼
        fixed = content.replace('\n', ' ').replace('\r', ' ')
        # å‹ç¼©å¤šä½™ç©ºæ ¼
        fixed = re.sub(r'\s+', ' ', fixed)
        return fixed
    
    # åŒ¹é… JSON å­—ç¬¦ä¸²ï¼ˆè€ƒè™‘è½¬ä¹‰å¼•å·ï¼‰
    json_str = re.sub(r'"(?:[^"\\]|\\.)*"', fix_string_newlines, json_str)
    
    # 2. ç§»é™¤æ§åˆ¶å­—ç¬¦
    json_str = re.sub(r'[\x00-\x1f\x7f]', ' ', json_str)
    
    # 3. ä¿®å¤å¸¸è§çš„ Unicode é—®é¢˜
    json_str = json_str.replace('\u2028', ' ').replace('\u2029', ' ')
    
    return json_str


def normalize_plan_data(data: dict, destination: str) -> dict:
    """æ ‡å‡†åŒ–æ•°æ®ï¼Œç¡®ä¿ç¬¦åˆ TravelPlanResult schema"""
    
    result = {
        "overview": "",
        "destination": destination,  # âœ… ç¡®ä¿åŒ…å« destination
        "highlights": [],
        "days": [],
        "tips": {}
    }
    
    # 1. ä¿®å¤ overview
    overview = data.get("overview", "")
    if isinstance(overview, dict):
        result["overview"] = overview.get("summary", f"{destination}ç²¾å½©ä¹‹æ—…")
    elif isinstance(overview, str):
        result["overview"] = overview
    else:
        result["overview"] = f"{destination}ç²¾å½©ä¹‹æ—…"
    
    # 2. ä¿®å¤ highlights
    highlights = data.get("highlights", [])
    if isinstance(highlights, list):
        result["highlights"] = [str(h) for h in highlights if h]
    else:
        result["highlights"] = []
    
    # 3. ä¿®å¤ days
    days = data.get("days", [])
    fixed_days = []
    
    for day in days:
        fixed_day = {
            "day": day.get("day", len(fixed_days) + 1),
            "date": day.get("date", f"Day {len(fixed_days) + 1}"),
            "theme": day.get("theme", ""),
            "weather_tip": day.get("weather_tip", ""),
            "schedule": []
        }
        
        schedule = day.get("schedule", [])
        for item in schedule:
            fixed_item = normalize_schedule_item(item)
            if fixed_item:
                fixed_day["schedule"].append(fixed_item)
        
        fixed_days.append(fixed_day)
    
    result["days"] = fixed_days
    
    # 4. ä¿®å¤ tips
    tips = data.get("tips", {})
    if isinstance(tips, dict):
        result["tips"] = {
            "transport": _to_string(tips.get("transport", "")),
            "food": _to_string(tips.get("food", "")),
            "accommodation": _to_string(tips.get("accommodation", "")),
            "budget": _to_string(tips.get("budget", "")),
            "avoid": _to_list(tips.get("avoid", [])),
            "replaceable": _to_list(tips.get("replaceable", [])),
        }
    else:
        result["tips"] = {
            "transport": "",
            "food": "",
            "avoid": [],
            "replaceable": []
        }
    
    return result


def normalize_schedule_item(item: dict) -> Optional[dict]:
    """æ ‡å‡†åŒ–å•ä¸ªè¡Œç¨‹é¡¹"""
    if not isinstance(item, dict):
        return None
    
    # âœ… å…³é”®ï¼štips å¿…é¡»æ˜¯å­—ç¬¦ä¸²
    tips = item.get("tips", "")
    if isinstance(tips, list):
        tips = "ï¼›".join(str(t) for t in tips)  # åˆ—è¡¨è½¬å­—ç¬¦ä¸²
    elif not isinstance(tips, str):
        tips = str(tips) if tips else ""
    
    return {
        "time": item.get("time", "å¾…å®š"),
        "poi": _get_poi(item),
        "activity": item.get("activity", item.get("description", "")),
        "duration": item.get("duration", "1å°æ—¶"),
        "tips": tips,  # âœ… ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        "route_info": item.get("route_info", item.get("transport", ""))
    }


def _get_poi(item: dict) -> str:
    """ä» item ä¸­æå– POI åç§°"""
    poi = (
        item.get("poi") or 
        item.get("location") or 
        item.get("name") or 
        item.get("place") or
        ""
    )
    
    # å¦‚æœè¿˜æ˜¯ç©ºçš„ï¼Œå°è¯•ä» activity ä¸­æå–
    if not poi:
        activity = item.get("activity", "")
        for keyword in ["æ¸¸è§ˆ", "å‰å¾€", "åˆ°è¾¾", "å‚è§‚"]:
            if keyword in activity:
                parts = activity.split(keyword)
                if len(parts) > 1:
                    poi = parts[1].split("ï¼Œ")[0].split("ï¼ˆ")[0].strip()[:20]
                    break
    
    return poi if poi else "å¾…å®šåœ°ç‚¹"


def _to_string(value: Any) -> str:
    """å°†ä»»æ„å€¼è½¬ä¸ºå­—ç¬¦ä¸²"""
    if isinstance(value, list):
        return "ï¼›".join(str(v) for v in value)
    elif isinstance(value, dict):
        return json.dumps(value, ensure_ascii=False)
    elif value is None:
        return ""
    else:
        return str(value)


def _to_list(value: Any) -> List[str]:
    """å°†ä»»æ„å€¼è½¬ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨"""
    if isinstance(value, list):
        return [str(v) for v in value]
    elif isinstance(value, str):
        return [value] if value else []
    else:
        return []


def _save_to_cache(state: AgentState) -> bool:
    """
    å°†æœ€ç»ˆç»“æœä¿å­˜åˆ° Redis
    
    Args:
        state: Agent çŠ¶æ€
        
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    # âœ… ä» state è·å– session_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»ä¸Šä¸‹æ–‡è·å–
    session_id = state.get("session_id") or get_session_id()
    
    if not session_id:
        print("âš ï¸ æ— æ³•ä¿å­˜ï¼šsession_id ä¸ºç©º")
        return False
    
    final_result = state.get("final_result")
    if not final_result:
        print("âš ï¸ æ— æ³•ä¿å­˜ï¼šfinal_result ä¸ºç©º")
        return False
    
    # è½¬æ¢ç»“æœä¸ºå­—å…¸
    if hasattr(final_result, 'model_dump'):
        result_dict = final_result.model_dump()
    elif hasattr(final_result, 'dict'):
        result_dict = final_result.dict()
    else:
        result_dict = final_result
    
    # è·å–ç”¨æˆ·ç”»åƒ
    user_profile = state.get("user_profile")
    user_profile_dict = None
    if user_profile:
        if hasattr(user_profile, 'model_dump'):
            user_profile_dict = user_profile.model_dump()
        elif hasattr(user_profile, 'dict'):
            user_profile_dict = user_profile.dict()
        else:
            user_profile_dict = user_profile
    
    # æ„å»ºå®Œæ•´çš„å­˜å‚¨æ•°æ®
    plan_data = {
        "plan": result_dict,
        "user_profile": user_profile_dict,
        "destination": user_profile.destination if user_profile else "æœªçŸ¥",
        "days": user_profile.days if user_profile else 0,
        "meta": {
            "search_count": state.get("_search_count", 0),
            "has_weather": state.get("weather_info") is not None,
            "has_map_validation": state.get("validated_plan") is not None,
        },
        "generated_at": datetime.now().isoformat()
    }
    
    # âœ… ä¿å­˜åˆ° Redis
    success = redis_service.save_plan(session_id, plan_data)
    
    if success:
        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        redis_service.update_plan_status(
            session_id,
            status="completed",
            progress=100,
            message="æ—…è¡Œè®¡åˆ’ç”Ÿæˆå®Œæˆ"
        )
        print(f"âœ… è®¡åˆ’å·²ä¿å­˜åˆ° Redisï¼Œsession_id: {session_id}")
    
    return success


def create_empty_result(destination: str, days: int) -> TravelPlanResult:
    """åˆ›å»ºç©ºç»“æœ"""
    return TravelPlanResult(
        destination=destination,
        title=f"{destination}{days}æ—¥æ¸¸",
        summary="æš‚æ— è¡Œç¨‹ä¿¡æ¯",
        highlights=[],
        daily_plans=[],
        tips=[],
        estimated_budget=""
    )


def create_fallback_result(state: AgentState, plan, destination: str, days_count: int) -> TravelPlanResult:
    """åˆ›å»ºå…œåº•çš„æ—…è¡Œç»“æœ"""
    from datetime import datetime
    
    # è·å–ç”¨æˆ·ä¿¡æ¯
    user_profile = state.get("user_profile")
    planning_rules = state.get("planning_rules")
    
    # æ„å»ºæ¯æ—¥è¡Œç¨‹
    daily_plans = []
    if plan and hasattr(plan, 'daily_plans') and plan.daily_plans:
        daily_plans = plan.daily_plans
    else:
        # åˆ›å»ºé»˜è®¤æ¯æ—¥è¡Œç¨‹
        for i in range(days_count):
            daily_plans.append(DailyPlan(
                day=i + 1,
                date=f"ç¬¬{i + 1}å¤©",
                theme=f"Day {i + 1} è¡Œç¨‹",
                activities=[],
                meals={},
                tips=[]
            ))
    
    # âœ… æ ¹æ®ä½ çš„ TravelTips æ¨¡å‹æ„å»º
    tips = TravelTips(
        transport="",
        food="",
        accommodation="",
        budget="",
        avoid=[],
        replaceable=[]
    )
    
    # ä» planning_rules å¡«å…… tips
    if planning_rules:
        # äº¤é€šå»ºè®®
        if planning_rules.transport_tips:
            tips.transport = "ï¼›".join(planning_rules.transport_tips[:3])
        
        # ç¾é£Ÿå»ºè®®
        if planning_rules.food_accommodation:
            fa = planning_rules.food_accommodation
            food_items = []
            if hasattr(fa, 'food_areas') and fa.food_areas:
                food_items.extend(fa.food_areas[:2])
            if hasattr(fa, 'recommendations') and fa.recommendations:
                food_items.extend(fa.recommendations[:2])
            tips.food = "ï¼›".join(food_items) if food_items else ""
            
            # ä½å®¿å»ºè®®
            if hasattr(fa, 'stay_areas') and fa.stay_areas:
                tips.accommodation = "ï¼›".join(fa.stay_areas[:2])
        
        # é¿å‘å»ºè®®
        if hasattr(planning_rules, 'avoid') and planning_rules.avoid:
            tips.avoid = planning_rules.avoid[:5]
        elif hasattr(planning_rules, 'avoid_list') and planning_rules.avoid_list:
            # ä» avoid_list æå–
            avoid_items = []
            for item in planning_rules.avoid_list[:5]:
                if isinstance(item, str):
                    avoid_items.append(item)
                elif isinstance(item, dict):
                    avoid_items.append(item.get("item", str(item)))
                elif hasattr(item, 'item'):
                    avoid_items.append(item.item)
            tips.avoid = avoid_items
        
        # å®ç”¨å»ºè®®ä½œä¸ºå¯æ›¿æ¢é¡¹
        if planning_rules.practical_tips:
            tips.replaceable = planning_rules.practical_tips[:3]
    
    # æ„å»ºç»“æœ
    return TravelPlanResult(
        destination=destination,
        duration=f"{days_count}å¤©",
        travel_dates=user_profile.travel_dates if user_profile else "",
        daily_plans=daily_plans,
        tips=tips,  # âœ… ä¼ å…¥ TravelTips å¯¹è±¡
        summary=f"{destination}{days_count}å¤©è¡Œç¨‹è§„åˆ’",
        budget_estimate=None,
        weather_summary=None,
        created_at=datetime.now().isoformat()
    )

# ============ è¾…åŠ©å‡½æ•° ============

def get_geocode(address: str, city: str = "") -> dict:
    """è·å–åœ°å€çš„ç»çº¬åº¦åæ ‡"""
    geo_tool = GeoCodeTool()
    try:
        result = geo_tool._run(address=address, city=city)
        return json.loads(result)
    except Exception as e:
        return {"error": str(e)}


def get_route_info(origin: str, destination: str, mode: str = "driving") -> dict:
    """è·å–ä¸¤ç‚¹é—´çš„è·¯çº¿ä¿¡æ¯"""
    route_tool = RoutePlanTool()
    try:
        result = route_tool._run(origin=origin, destination=destination, mode=mode)
        return json.loads(result)
    except Exception as e:
        return {"error": str(e)}